#!/usr/bin/env groovy

@Library('apm@current') _

pipeline {
  agent { label 'ubuntu-20 && immutable' }
  environment {
    BRANCH_NAME_LOWER_CASE = "${env.BRANCH_NAME.toLowerCase().replaceAll('[^a-z0-9-]', '-')}"
    CREATED_DATE = "${new Date().getTime()}"
    ENVIRONMENT = "ci"
    REPO = 'integrations'
    BASE_DIR = "src/github.com/elastic/${REPO}"
    GITHUB_TOKEN_CREDENTIALS = "2a9602aa-ab9f-4e52-baf3-b71ca88469c7"
    JOB_GIT_CREDENTIALS = "f6c7695a-671e-4f4f-a331-acdce44ff9ba"
    PACKAGE_STORAGE_BASE_DIR = "src/github.com/elastic/package-storage"
    AWS_ACCOUNT_SECRET = "secret/observability-team/ci/elastic-observability-aws-account-auth"
    HOME = "${env.WORKSPACE}"
    KIND_VERSION = "v0.14.0"
    K8S_VERSION = "v1.24.0"
    JOB_GCS_BUCKET = 'beats-ci-temp'
    JOB_GCS_BUCKET_INTERNAL = 'beats-ci-temp-internal'
    JOB_GCS_CREDENTIALS = 'beats-ci-gcs-plugin'
    JOB_GCS_EXT_CREDENTIALS = 'beats-ci-gcs-plugin-file-credentials'
    STACK_VERSION = "${params.stackVersion}"
  }
  options {
    timeout(time: 2, unit: 'HOURS')
    buildDiscarder(logRotator(numToKeepStr: '20', artifactNumToKeepStr: '20', daysToKeepStr: '30'))
    timestamps()
    ansiColor('xterm')
    disableResume()
    durabilityHint('PERFORMANCE_OPTIMIZED')
    rateLimitBuilds(throttle: [count: 60, durationName: 'hour', userBoost: true])
    quietPeriod(10)
  }
  triggers {
    issueCommentTrigger("${obltGitHubComments()}")
  }
  parameters {
    string(name: 'stackVersion', defaultValue: '', description: 'Version of the stack to use for testing.')
  }
  stages {
    stage('Prepare workspace') {
      steps {
        deleteDir()
        gitCheckout(basedir: "${BASE_DIR}")
        stashV2(name: 'source', bucket: "${JOB_GCS_BUCKET}", credentialsId: "${JOB_GCS_CREDENTIALS}")
      }
    }
    stage('Check Go sources') {
      steps {
        dir("${BASE_DIR}"){
          withMageEnv(){
            sh(label: 'Checks and builds Go sources', script: 'mage -debug check')
            checkGitDiff()
          }
        }
      }
    }
    stage('Check integrations') {
      steps {
        script {
          dir("${BASE_DIR}/packages") {
            def integrations = [:]
            // Include hack to skip temporary files with "@tmp" suffix.
            // For reference: https://issues.jenkins.io/browse/JENKINS-52750
            findFiles()?.findAll{ !it.name.endsWith('@tmp') }?.collect{ it.name }?.sort()?.each {
              if (isPrAffected(it)) {
                integrations[it] = {
                  withNode(labels: 'ubuntu-20 && immutable', sleepMin: 10, sleepMax: 100) {
                    stage("${it}: check") {
                      deleteDir()
                      unstashV2(name: 'source', bucket: "${JOB_GCS_BUCKET}", credentialsId: "${JOB_GCS_CREDENTIALS}")
                      useElasticPackage()
                      try {
                        dir("${BASE_DIR}/packages/${it}") {
                          sh(label: "Check integration: ${it}", script: '../../build/elastic-package check -v')
                          prepareStack()
                          withKubernetes() {
                            withSecretVault(secret: "${AWS_ACCOUNT_SECRET}", data: ['access_key': 'AWS_ACCESS_KEY_ID', 'secret_key': 'AWS_SECRET_ACCESS_KEY']) {
                              sh(label: "Test integration: ${it}", script: '''
                                eval "$(../../build/elastic-package stack shellinit)"
                                ../../build/elastic-package test -v --report-format xUnit --report-output file --test-coverage
                                ''')
                            }
                          }

                          // Publish package to the Package Storage
                          if (env.BRANCH_NAME == 'main') {
                            withCredentials([string(credentialsId: "${GITHUB_TOKEN_CREDENTIALS}", variable: 'GITHUB_TOKEN')]) {
                              sh(label: 'Configure Git user.name', script: 'git config --global user.name "Elastic Machine"')
                              sh(label: 'Configure Git user.email', script: 'git config --global user.email "elasticmachine@users.noreply.github.com"')
                              sh(label: "Publish integration: ${it}", script: '../../build/elastic-package publish -v --fork=false')
                            }
                          }
                        }
                      } finally {
                        dir("${BASE_DIR}") {
                          archiveArtifacts(allowEmptyArchive: true, artifacts: 'build/test-results/*.xml')
                          junit(allowEmptyResults: true, keepLongStdio: true, testResults: "build/test-results/*.xml")
                          sh(label: "Collect Elastic stack logs", script: "build/elastic-package stack dump -v --output build/elastic-stack-dump/${it}")
                          archiveArtifacts(allowEmptyArchive: true, artifacts: "build/elastic-stack-dump/${it}/logs/*.log, build/elastic-stack-dump/${it}/logs/fleet-server-internal/*")
                          archiveArtifactsSafe("insecure-logs/${it}", "build/elastic-stack-dump/${it}/logs/elastic-agent-internal/*")
                          archiveArtifactsSafe("insecure-logs/${it}/container-logs", "build/container-logs/*.log")
                          sh(label: "Take down the Elastic stack", script: 'build/elastic-package stack down -v')
                          stashCoverageReport()
                        }
                      }
                    }
                  }
                }
              }
            }
            parallel integrations
          }
        }
      }
    }
  }
  post {
    always {
      publishCoverageReports()
    }
    cleanup {
      notifyBuildResult(prComment: true)
    }
  }
}

def cleanup(){
  dir("${BASE_DIR}"){
    deleteDir()
  }
}

def useElasticPackage() {
  withGoEnv() {
    dir("${BASE_DIR}/build") {
      sh(label: 'Install elastic-package', script: 'go build github.com/elastic/elastic-package')
    }
  }
}

// Check if there are non-versioned local changes.
// For reference: https://stackoverflow.com/questions/34807971/why-does-git-diff-index-head-result-change-for-touched-files-after-git-diff-or-g
def checkGitDiff() {
  dir("${BASE_DIR}") {
    sh(label: "git update-index", script: 'git update-index --refresh')
    sh(label: "git diff-index", script: 'git diff-index --exit-code HEAD --')
  }
}

def isPrAffected(integrationName) {
  def manifest = readYaml(file: "${integrationName}/manifest.yml")

  // Packages supported in Kibana >= 8.0.0, shouldn't be included in daily tests of the stack 7.x
  if (manifest != null && manifest['conditions'] != null) {
    def kibanaVersionCondition = manifest['conditions']['kibana.version']
    if (kibanaVersionCondition != null) {
      if (!kibanaVersionCondition.contains('^7.') && "${env.STACK_VERSION}".startsWith('7.')) {
        echo "[${integrationName}] PR is not affected: unsupported stack (7.x)"
        return false
      }
      if (!kibanaVersionCondition.contains('^8.') && "${env.STACK_VERSION}".startsWith('8.')) {
        echo "[${integrationName}] PR is not affected: unsupported stack (8.x)"
        return false
      }
    }
  }

  if (env.BRANCH_NAME == "main") {
    echo "[${integrationName}] PR is affected: running on main branch"
    return true
  }

  // Source: https://github.com/elastic/apm-pipeline-library/blob/721115cf0fdb2b5a4e1cb6a576bfbb7035d14485/vars/getGitMatchingGroup.groovy#L40-L41
  def from = env.CHANGE_TARGET?.trim() ? "origin/${env.CHANGE_TARGET}" : "${env.GIT_PREVIOUS_COMMIT?.trim() ? env.GIT_PREVIOUS_COMMIT : env.GIT_BASE_COMMIT}"
  def to = env.GIT_BASE_COMMIT

  def r = sh(label: "[${integrationName}] git-diff: check non-package files", script: "git diff --name-only \$(git merge-base ${from} ${to}) ${to} | egrep -v '^(packages/|.github/CODEOWNERS)'", returnStatus: true)
  if (r == 0) {
    echo "[${integrationName}] PR is affected: found non-package files"
    return true
  }

  r = sh(label: "[${integrationName}] git-diff: check package files", script: "git diff --name-only \$(git merge-base ${from} ${to}) ${to} | egrep '^packages/${integrationName}/'", returnStatus: true)
  if (r == 0) {
    echo "[${integrationName}] PR is affected: found package files"
    return true
  }

  echo "[${integrationName}] PR is not affected"
  return false
}

def withKubernetes(Closure body) {
    def r = sh(label: "git-diff: check if Kubernetes service deployer is used",
               script: "find . -type d | egrep '_dev/deploy/k8s\$'",
               returnStatus: true)
    withEnv(["PATH=${env.WORKSPACE}/bin:${env.PATH}"]) {
      if (r == 0) {
        retryWithSleep(retries: 2, seconds: 5, backoff: true) { sh(label: "Install kind", script: '''
          mkdir -p ${HOME}/bin
          curl -sSLo ${HOME}/bin/kind "https://github.com/kubernetes-sigs/kind/releases/download/${KIND_VERSION}/kind-linux-amd64"
          chmod +x ${HOME}/bin/kind
          kind version
          ''') }
        retryWithSleep(retries: 2, seconds: 5, backoff: true) { sh(label: "Install kubectl", script: '''
          mkdir -p ${HOME}/bin
          curl -sSLo ${HOME}/bin/kubectl "https://storage.googleapis.com/kubernetes-release/release/${K8S_VERSION}/bin/linux/amd64/kubectl"
          chmod +x ${HOME}/bin/kubectl
          kubectl version --client
          ''') }
        sh(label: "Create kind cluster", script: 'kind create cluster --config ../../kind-config.yaml')
      }

      try {
        body()
      } catch(error) {
        throw error // rethrow error up if there is any, but delete k8s cluster first
      } finally {
        if (r == 0) {
          sh(label: "Delete kind cluster", script: 'kind delete cluster')
        }
      }
    }
}

def prepareStack() {
  def stackArgs = '-v'

  if ( env.STACK_VERSION?.trim() ) {
    stackArgs += " --version ${env.STACK_VERSION}"
  } else {
    def manifest = readYaml(file: "manifest.yml")

    if (manifest != null && manifest["conditions"] != null) {
      def kibanaVersionCondition = manifest["conditions"]["kibana.version"]
      if (kibanaVersionCondition != null) {
        def version = findOldestSupportedVersion(versionCondition: kibanaVersionCondition)
        stackArgs += " --version ${version}"
      }
    }
  }

  sh(label: "Update the Elastic stack", script: "../../build/elastic-package stack update ${stackArgs}")
  sh(label: "Boot up the Elastic stack", script: "../../build/elastic-package stack up -d ${stackArgs}")
}

def stashCoverageReport() {
  r = sh(label: "isCoverageReportPresent", script: "ls build/test-coverage/*.xml", returnStatus: true)
  if (r != 0) {
    echo "isCoverageReportPresent: coverage files not found, report won't be stashed"
    return
  }

  googleStorageUploadExt(bucket: getCoverageBucketURI(), credentialsId: "${JOB_GCS_EXT_CREDENTIALS}", pattern: "build/test-coverage/*.xml")
}

def publishCoverageReports() {
  stage('Publish coverage reports') {
    dir("${BASE_DIR}") {
      def bucketUri = getCoverageBucketURI() + "*.xml"
      googleStorageDownload(bucketUri: bucketUri, credentialsId: "${JOB_GCS_CREDENTIALS}", localDirectory: 'build/test-coverage', pathPrefix: getCoveragePathPrefix())
      coverageReport('build/test-coverage')
    }
  }
}

def getCoverageBucketURI() {
  return "gs://${JOB_GCS_BUCKET}/" + getCoveragePathPrefix()
}

def getCoveragePathPrefix() {
  return "${env.JOB_NAME}-${env.BUILD_ID}/test-coverage/"
}

def archiveArtifactsSafe(remotePath, artifacts) {
  r = sh(label: "areArtifactsPresent", script: "ls ${artifacts}", returnStatus: true)
  if (r != 0) {
    echo "areArtifactsPresent: artifacts files not found, nothing will be archived"
    return
  }

  googleStorageUploadExt(
    bucket: "gs://${JOB_GCS_BUCKET_INTERNAL}/${env.JOB_NAME}-${env.BUILD_ID}/${remotePath}",
    credentialsId: "${JOB_GCS_EXT_CREDENTIALS}",
    pattern: artifacts)
}
