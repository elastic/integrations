#!/usr/bin/env groovy

@Library('apm@current') _

pipeline {
  agent { label 'ubuntu-20 && immutable' }
  environment {
    BRANCH_NAME_LOWER_CASE = "${env.BRANCH_NAME.toLowerCase().replaceAll('[^a-z0-9-]', '-')}"
    CREATED_DATE = "${new Date().getTime()}"
    ENVIRONMENT = "ci"
    REPO = 'integrations'
    REPO_BUILD_TAG = "${env.REPO}/${env.BUILD_TAG}"
    BASE_DIR = "src/github.com/elastic/${REPO}"
    GITHUB_TOKEN_CREDENTIALS = "2a9602aa-ab9f-4e52-baf3-b71ca88469c7"
    JOB_GIT_CREDENTIALS = "f6c7695a-671e-4f4f-a331-acdce44ff9ba"
    PACKAGE_STORAGE_BASE_DIR = "src/github.com/elastic/package-storage"
    AWS_ACCOUNT_SECRET = "secret/observability-team/ci/elastic-observability-aws-account-auth"
    HOME = "${env.WORKSPACE}"
    KIND_VERSION = "v0.14.0"
    K8S_VERSION = "v1.24.0"
    JOB_GCS_BUCKET = 'beats-ci-temp'
    JOB_GCS_BUCKET_INTERNAL = 'beats-ci-temp-internal'
    JOB_GCS_CREDENTIALS = 'beats-ci-gcs-plugin'
    JOB_GCS_EXT_CREDENTIALS = 'beats-ci-gcs-plugin-file-credentials'
    STACK_VERSION = "${params.stackVersion}"

    // Signing
    JOB_SIGNING_CREDENTIALS = 'sign-artifacts-with-gpg-job'
    INFRA_SIGNING_BUCKET_NAME = 'internal-ci-artifacts'
    INFRA_SIGNING_BUCKET_SIGNED_ARTIFACTS_SUBFOLDER = "${env.REPO_BUILD_TAG}/signed-artifacts"
    INFRA_SIGNING_BUCKET_ARTIFACTS_PATH = "gs://${env.INFRA_SIGNING_BUCKET_NAME}/${env.REPO_BUILD_TAG}"
    INFRA_SIGNING_BUCKET_SIGNED_ARTIFACTS_PATH = "gs://${env.INFRA_SIGNING_BUCKET_NAME}/${env.INFRA_SIGNING_BUCKET_SIGNED_ARTIFACTS_SUBFOLDER}"

    // Publishing
    INTERNAL_CI_JOB_GCS_CREDENTIALS = 'internal-ci-gcs-plugin'
    PACKAGE_STORAGE_UPLOADER_CREDENTIALS = 'upload-package-to-package-storage'
    PACKAGE_STORAGE_UPLOADER_GCP_SERVICE_ACCOUNT = 'secret/gce/elastic-bekitzur/service-account/package-storage-uploader'
    PACKAGE_STORAGE_INTERNAL_BUCKET_QUEUE_PUBLISHING_PATH = "gs://elastic-bekitzur-package-storage-internal/queue-publishing/${env.REPO_BUILD_TAG}"
  }
  options {
    timeout(time: 4, unit: 'HOURS')
    buildDiscarder(logRotator(numToKeepStr: '20', artifactNumToKeepStr: '20', daysToKeepStr: '30'))
    timestamps()
    ansiColor('xterm')
    disableResume()
    durabilityHint('PERFORMANCE_OPTIMIZED')
    rateLimitBuilds(throttle: [count: 60, durationName: 'hour', userBoost: true])
    quietPeriod(10)
  }
  triggers {
    issueCommentTrigger("${obltGitHubComments()}")
  }
  parameters {
    string(name: 'stackVersion', defaultValue: '', description: 'Version of the stack to use for testing.')
  }
  stages {
    stage('Prepare workspace') {
      steps {
        deleteDir()
        gitCheckout(basedir: "${BASE_DIR}")
        stashV2(name: 'source', bucket: "${JOB_GCS_BUCKET}", credentialsId: "${JOB_GCS_CREDENTIALS}")
      }
    }
    stage('Check Go sources') {
      steps {
        dir("${BASE_DIR}"){
          withMageEnv(){
            sh(label: 'Checks and builds Go sources', script: 'mage -debug check')
            checkGitDiff()
          }
        }
      }
    }
    stage('Check integrations') {
      steps {
        script {
          dir("${BASE_DIR}/packages") {
            def integrations = [:]
            // Include hack to skip temporary files with "@tmp" suffix.
            // For reference: https://issues.jenkins.io/browse/JENKINS-52750
            findFiles()?.findAll{ !it.name.endsWith('@tmp') }?.collect{ it.name }?.sort()?.each {
              if (isPrAffected(it)) {
                integrations[it] = {
                  withNode(labels: 'ubuntu-20 && immutable', sleepMin: 10, sleepMax: 100) {
                    stage("${it}: check") {
                      deleteDir()
                      unstashV2(name: 'source', bucket: "${JOB_GCS_BUCKET}", credentialsId: "${JOB_GCS_CREDENTIALS}")
                      useElasticPackage()
                      try {
                        dir("${BASE_DIR}/packages/${it}") {
                          sh(label: "Check integration: ${it}", script: '../../build/elastic-package check -v')
                          prepareStack()
                          withKubernetes() {
                            withSecretVault(secret: "${AWS_ACCOUNT_SECRET}", data: ['access_key': 'AWS_ACCESS_KEY_ID', 'secret_key': 'AWS_SECRET_ACCESS_KEY']) {
                              sh(label: "Test integration: ${it}", script: '''
                                eval "$(../../build/elastic-package stack shellinit)"
                                ../../build/elastic-package test -v --report-format xUnit --report-output file --test-coverage
                                ''')
                            }
                          }

                          // Publish package to the Package Storage
                          if (env.BRANCH_NAME == 'main') {
                            withCredentials([string(credentialsId: "${GITHUB_TOKEN_CREDENTIALS}", variable: 'GITHUB_TOKEN')]) {
                              sh(label: 'Configure Git user.name', script: 'git config --global user.name "Elastic Machine"')
                              sh(label: 'Configure Git user.email', script: 'git config --global user.email "elasticmachine@users.noreply.github.com"')
                              sh(label: "Publish integration: ${it}", script: '../../build/elastic-package publish -v --fork=false')
                            }
                          }
                        }
                      } finally {
                        dir("${BASE_DIR}") {
                          archiveArtifacts(allowEmptyArchive: true, artifacts: 'build/test-results/*.xml')
                          junit(allowEmptyResults: true, keepLongStdio: true, testResults: "build/test-results/*.xml")
                          sh(label: "Collect Elastic stack logs", script: "build/elastic-package stack dump -v --output build/elastic-stack-dump/${it}")
                          archiveArtifacts(allowEmptyArchive: true, artifacts: "build/elastic-stack-dump/${it}/logs/*.log, build/elastic-stack-dump/${it}/logs/fleet-server-internal/*")
                          archiveArtifactsSafe("insecure-logs/${it}", "build/elastic-stack-dump/${it}/logs/elastic-agent-internal/*")
                          archiveArtifactsSafe("insecure-logs/${it}/container-logs", "build/container-logs/*.log")
                          sh(label: "Take down the Elastic stack", script: 'build/elastic-package stack down -v')
                          stashCoverageReport()
                        }
                      }
                    }
                  }
                }
              }
            }
            parallel integrations
          }
        }
      }
    }
  }
  post {
    always {
      publishCoverageReports()
      packageStoragePublish()
    }
    cleanup {
      notifyBuildResult(prComment: true)
    }
  }
}

def cleanup(){
  dir("${BASE_DIR}"){
    deleteDir()
  }
}

def useElasticPackage() {
  withGoEnv() {
    dir("${BASE_DIR}/build") {
      sh(label: 'Install elastic-package', script: 'go build github.com/elastic/elastic-package')
    }
  }
}

// Check if there are non-versioned local changes.
// For reference: https://stackoverflow.com/questions/34807971/why-does-git-diff-index-head-result-change-for-touched-files-after-git-diff-or-g
def checkGitDiff() {
  dir("${BASE_DIR}") {
    sh(label: "git update-index", script: 'git update-index --refresh')
    sh(label: "git diff-index", script: 'git diff-index --exit-code HEAD --')
  }
}

def isPrAffected(integrationName) {
  def manifest = readYaml(file: "${integrationName}/manifest.yml")

  // Packages supported in Kibana >= 8.0.0, shouldn't be included in daily tests of the stack 7.x
  if (manifest != null && manifest['conditions'] != null) {
    def kibanaVersionCondition = manifest['conditions']['kibana.version']
    if (kibanaVersionCondition != null) {
      if (!kibanaVersionCondition.contains('^7.') && "${env.STACK_VERSION}".startsWith('7.')) {
        echo "[${integrationName}] PR is not affected: unsupported stack (7.x)"
        return false
      }
      if (!kibanaVersionCondition.contains('^8.') && "${env.STACK_VERSION}".startsWith('8.')) {
        echo "[${integrationName}] PR is not affected: unsupported stack (8.x)"
        return false
      }
    }
  }

  if (env.BRANCH_NAME == "main") {
    echo "[${integrationName}] PR is affected: running on main branch"
    return true
  }

  // Source: https://github.com/elastic/apm-pipeline-library/blob/721115cf0fdb2b5a4e1cb6a576bfbb7035d14485/vars/getGitMatchingGroup.groovy#L40-L41
  def from = env.CHANGE_TARGET?.trim() ? "origin/${env.CHANGE_TARGET}" : "${env.GIT_PREVIOUS_COMMIT?.trim() ? env.GIT_PREVIOUS_COMMIT : env.GIT_BASE_COMMIT}"
  def to = env.GIT_BASE_COMMIT

  def r = sh(label: "[${integrationName}] git-diff: check non-package files", script: "git diff --name-only \$(git merge-base ${from} ${to}) ${to} | egrep -v '^(packages/|.github/CODEOWNERS)'", returnStatus: true)
  if (r == 0) {
    echo "[${integrationName}] PR is affected: found non-package files"
    return true
  }

  r = sh(label: "[${integrationName}] git-diff: check package files", script: "git diff --name-only \$(git merge-base ${from} ${to}) ${to} | egrep '^packages/${integrationName}/'", returnStatus: true)
  if (r == 0) {
    echo "[${integrationName}] PR is affected: found package files"
    return true
  }

  echo "[${integrationName}] PR is not affected"
  return false
}

def withKubernetes(Closure body) {
    def r = sh(label: "git-diff: check if Kubernetes service deployer is used",
               script: "find . -type d | egrep '_dev/deploy/k8s\$'",
               returnStatus: true)
    withEnv(["PATH=${env.WORKSPACE}/bin:${env.PATH}"]) {
      if (r == 0) {
        retryWithSleep(retries: 2, seconds: 5, backoff: true) { sh(label: "Install kind", script: '''
          mkdir -p ${HOME}/bin
          curl -sSLo ${HOME}/bin/kind "https://github.com/kubernetes-sigs/kind/releases/download/${KIND_VERSION}/kind-linux-amd64"
          chmod +x ${HOME}/bin/kind
          kind version
          ''') }
        retryWithSleep(retries: 2, seconds: 5, backoff: true) { sh(label: "Install kubectl", script: '''
          mkdir -p ${HOME}/bin
          curl -sSLo ${HOME}/bin/kubectl "https://storage.googleapis.com/kubernetes-release/release/${K8S_VERSION}/bin/linux/amd64/kubectl"
          chmod +x ${HOME}/bin/kubectl
          kubectl version --client
          ''') }
        sh(label: "Create kind cluster", script: 'kind create cluster --config ../../kind-config.yaml')
      }

      try {
        body()
      } catch(error) {
        throw error // rethrow error up if there is any, but delete k8s cluster first
      } finally {
        if (r == 0) {
          sh(label: "Delete kind cluster", script: 'kind delete cluster')
        }
      }
    }
}

def prepareStack() {
  def stackArgs = '-v'

  if ( env.STACK_VERSION?.trim() ) {
    stackArgs += " --version ${env.STACK_VERSION}"
  } else {
    def manifest = readYaml(file: "manifest.yml")

    if (manifest != null && manifest["conditions"] != null) {
      def kibanaVersionCondition = manifest["conditions"]["kibana.version"]
      if (kibanaVersionCondition != null) {
        def version = findOldestSupportedVersion(versionCondition: kibanaVersionCondition)
        stackArgs += " --version ${version}"
      }
    }
  }

  sh(label: "Update the Elastic stack", script: "../../build/elastic-package stack update ${stackArgs}")
  sh(label: "Boot up the Elastic stack", script: "../../build/elastic-package stack up -d ${stackArgs}")
}

def stashCoverageReport() {
  r = sh(label: "isCoverageReportPresent", script: "ls build/test-coverage/*.xml", returnStatus: true)
  if (r != 0) {
    echo "isCoverageReportPresent: coverage files not found, report won't be stashed"
    return
  }

  googleStorageUploadExt(bucket: getCoverageBucketURI(), credentialsId: "${JOB_GCS_EXT_CREDENTIALS}", pattern: "build/test-coverage/*.xml")
}

def publishCoverageReports() {
  stage('Publish coverage reports') {
    dir("${BASE_DIR}") {
      def bucketUri = getCoverageBucketURI() + "*.xml"
      googleStorageDownload(bucketUri: bucketUri, credentialsId: "${JOB_GCS_CREDENTIALS}", localDirectory: 'build/test-coverage', pathPrefix: getCoveragePathPrefix())
      coverageReport('build/test-coverage')
    }
  }
}

def getCoverageBucketURI() {
  return "gs://${JOB_GCS_BUCKET}/" + getCoveragePathPrefix()
}

def getCoveragePathPrefix() {
  return "${env.JOB_NAME}-${env.BUILD_ID}/test-coverage/"
}

def archiveArtifactsSafe(remotePath, artifacts) {
  r = sh(label: "areArtifactsPresent", script: "ls ${artifacts}", returnStatus: true)
  if (r != 0) {
    echo "areArtifactsPresent: artifacts files not found, nothing will be archived"
    return
  }

  googleStorageUploadExt(
    bucket: "gs://${JOB_GCS_BUCKET_INTERNAL}/${env.JOB_NAME}-${env.BUILD_ID}/${remotePath}",
    credentialsId: "${JOB_GCS_EXT_CREDENTIALS}",
    pattern: artifacts)
}

def packageStoragePublish() {
  stage('Publish to Package Storage v2') {
    if (env.BRANCH_NAME != 'main') {
      echo "packageStoragePublish: not the main branch, nothing will be published"
      return
    }

    deleteDir()
    unstashV2(name: 'source', bucket: "${JOB_GCS_BUCKET}", credentialsId: "${JOB_GCS_CREDENTIALS}")
    useElasticPackage()

    // Build only unpublished files (need to read version from manifest.yml)
    def unpublishedPresent = false
    dir("${BASE_DIR}/packages") {
      findFiles()?.findAll{ !it.name.endsWith('@tmp') }?.collect{ it.name }?.sort()?.each {
        dir("${it}") {
          def manifest = readYaml(file: "manifest.yml")
          if (manifest != null && manifest["version"] != null) {
            def packageZip = it + "-" + manifest["version"] + ".zip"
            if (isAlreadyPublished(packageZip)) {
              return
            }
          }

          withEnv(["PATH=${env.WORKSPACE}/${BASE_DIR}/build:${env.PATH}"]) {
            sh(label: "Build integration as zip: ${it}", script: "elastic-package build --zip")
          }
          unpublishedPresent = true
        }
      }
    }
    if (!unpublishedPresent) {
      echo 'All packages are in sync'
      return
    }

    // Sign unpublished packages
    dir("${BASE_DIR}/build/packages") {
      googleStorageUpload(bucket: "${env.INFRA_SIGNING_BUCKET_ARTIFACTS_PATH}",
        credentialsId: env.INTERNAL_CI_JOB_GCS_CREDENTIALS,
        pattern: '*.zip',
        sharedPublicly: false,
        showInline: true)
      withCredentials([string(credentialsId: env.JOB_SIGNING_CREDENTIALS, variable: 'TOKEN')]) {
        triggerRemoteJob(auth: CredentialsAuth(credentials: 'local-readonly-api-token'),
          job: 'https://internal-ci.elastic.co/job/elastic+unified-release+master+sign-artifacts-with-gpg',
          token: TOKEN,
          parameters: [
            gcs_input_path: env.INFRA_SIGNING_BUCKET_ARTIFACTS_PATH,
          ],
          useCrumbCache: false,
          useJobInfoCache: false)
      }
      googleStorageDownload(bucketUri: "${env.INFRA_SIGNING_BUCKET_SIGNED_ARTIFACTS_PATH}/*",
        credentialsId: env.INTERNAL_CI_JOB_GCS_CREDENTIALS,
        localDirectory: '.',
        pathPrefix: "${env.INFRA_SIGNING_BUCKET_SIGNED_ARTIFACTS_SUBFOLDER}")
        sh(label: 'Rename .asc to .sig', script: 'for f in *.asc; do mv "$f" "${f%.asc}.sig"; done')
    }

    // Publish packages with signatures. Only packages with generated signatures haven't been published yet.
    withGCPEnv(secret: env.PACKAGE_STORAGE_UPLOADER_GCP_SERVICE_ACCOUNT) {
      withCredentials([string(credentialsId: env.PACKAGE_STORAGE_UPLOADER_CREDENTIALS, variable: 'TOKEN')]) {
        dir("${BASE_DIR}/build/packages") {
          findFiles()?.findAll{ it.name.endsWith('.zip') }?.collect{ it.name }?.sort()?.each {
            def packageZip = it
            def packageZipSig = packageZip + ".sig"
            sh(label: 'Upload package .zip file', script: "gsutil cp ${packageZip} ${env.PACKAGE_STORAGE_INTERNAL_BUCKET_QUEUE_PUBLISHING_PATH}/")
            sh(label: 'Upload package .sig file', script: "gsutil cp ${packageZipSig} ${env.PACKAGE_STORAGE_INTERNAL_BUCKET_QUEUE_PUBLISHING_PATH}/")
            triggerRemoteJob(auth: CredentialsAuth(credentials: 'local-readonly-api-token'),
              job: 'https://internal-ci.elastic.co/job/package_storage/job/publishing-job-remote',
              token: TOKEN,
              parameters: [
                dry_run: false,
                gs_package_build_zip_path: "${env.PACKAGE_STORAGE_INTERNAL_BUCKET_QUEUE_PUBLISHING_PATH}/${packageZip}",
                gs_package_signature_path: "${env.PACKAGE_STORAGE_INTERNAL_BUCKET_QUEUE_PUBLISHING_PATH}/${packageZipSig}"
              ],
              useCrumbCache: true,
              useJobInfoCache: true)
          }
        }
      }
    }
  }
}

def isAlreadyPublished(packageZip) {
  def responseCode = httpRequest(method: "HEAD",
    url: "https://package-storage.elastic.co/artifacts/packages/${packageZip}",
    response_code_only: true)
  if (responseCode != 200) {
    echo "Package Registry HTTP status code for ${packageZip}: ${responseCode}"
  }
  return responseCode == 200
}
