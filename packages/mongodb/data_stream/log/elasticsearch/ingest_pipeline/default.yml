---
description: Pipeline for parsing MongoDB logs
processors:
- set:
    field: event.ingested
    value: '{{_ingest.timestamp}}'
- rename:
    field: '@timestamp'
    target_field: event.created
- grok:
    field: message
    patterns:
    - ^%{CHAR:first_char}
    pattern_definitions:
      CHAR: .
- pipeline:
    if: ctx.first_char != '{'
    name: '{{ IngestPipeline "pipeline-plaintext" }}'
- pipeline:
    if: ctx.first_char == '{'
    name: '{{ IngestPipeline "pipeline-json" }}'
- set:
    field: event.kind
    value: event
- append:
    field: event.category
    value: database
- append:
    field: related.user
    value: "{{{ user.name }}}"
    allow_duplicates: false
    if: ctx.user?.name != null && ctx.user?.name != ''
- append:
    field: related.user
    value: "{{{ user.effective.name }}}"
    allow_duplicates: false
    if: ctx.user?.effective?.name != null && ctx.user?.effective?.name != ''
- append:
    field: related.ip
    value: "{{{ source.ip }}}"
    allow_duplicates: false
    if: ctx.source?.ip != null && ctx.source?.ip != ''
- append:
    field: related.hosts
    value: "{{{ host.hostname }}}"
    allow_duplicates: false
    if: ctx.host?.hostname != null && ctx.host?.hostname != ''
- remove:
    field:
    - first_char
on_failure:
- set:
    field: error.message
    value: '{{ _ingest.on_failure_message }}'
