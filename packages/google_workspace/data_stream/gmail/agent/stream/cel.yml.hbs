config_version: 2
resource.rate_limit.limit: {{resource_rate_limit_limit}}
resource.rate_limit.burst: {{resource_rate_limit_burst}}
interval: {{interval}}
resource.tracer:
  enabled: {{enable_request_tracer}}
  filename: "../../logs/cel/http-request-trace-*.ndjson"
  maxbackups: 5
{{#if proxy_url}}
resource.proxy_url: {{proxy_url}}
{{/if}}
{{#if ssl}}
resource.ssl: {{ssl}}
{{/if}}
{{#if http_client_timeout}}
resource.timeout: {{http_client_timeout}}
{{/if}}
auth.oauth2:
  provider: google
  google:
    jwt_file: {{jwt_file}}
    jwt_json: {{jwt_json}}
  scopes:
    - https://www.googleapis.com/auth/bigquery
resource.url: {{bigquery_endpoint}}
state:
  initial_interval: {{initial_interval}}
  lag_time: {{lag_time}}
  batch_size: {{batch_size}}
  project_id: !!str {{project_id}}
  dataset_name: {{dataset_name}}
  job_status_timeout: {{job_status_timeout}}
  location: {{location}}
redact:
  fields: ~
program: |
  // This CEL program defines the flow of operations for handling BigQuery jobs:
  // 1. Insert a BigQuery job.
  // 2. Periodically check whether the job has completed within a specified time bound.
  // 3. Cancel the job if the it has not completed within specified time bound.
  // 4. Fetch the job results if it has completed.
  (
    state.?next.job_status.orValue("") == "RUNNING" && state.?want_more.orValue(false) ?
      state
    :
      state.with({
        "start_time": state.?cursor.last_timestamp.orValue(
          timestamp(
            (now - duration(state.initial_interval) - duration(state.lag_time))
          ).as(ts,
            int(ts)*1000000+int(ts-timestamp(int(ts)))
          )
        ),
        "end_time": timestamp(
          (now - duration(state.lag_time))
        ).as(ts,
          int(ts)*1000000+int(ts-timestamp(int(ts)))
        ),
      })
  ).as(state, state.with(
    state.?next.job_id.hasValue() ? state :
      // Insert a query job to BigQuery.
      // The response for this request includes a unique job ID.
      // Job ID will be used to retrieve the query results.
      post_request(
        state.url.trim_right("/") + "/bigquery/v2/projects/" + state.project_id + "/jobs", "application/json", {
          "configuration": { "query": {
            "useLegacySql": false,
            // The activity table is an ingestion-time partitioned table,
            // which offers better query performance with pseudocolumns.
            // See https://cloud.google.com/bigquery/docs/querying-partitioned-tables.
            "query": "SELECT domain_name, email, event_id, event_name, event_type, has_sensitive_content, ip_address, record_type, time_usec, unique_identifier, gmail.event_info, gmail.message_info, resource_details FROM `"+
              string(state.project_id)+"."+string(state.dataset_name)+".activity`"+
              " WHERE _PARTITIONTIME >= TIMESTAMP('"+timestamp(int(state.start_time)/1000000).format(time_layout.DateOnly)+"')"+
              " AND time_usec > "+string(state.start_time)+
              " AND time_usec < "+string(state.end_time)+
              " AND record_type = 'gmail'"+
              " ORDER BY time_usec ASC",
          }},
          "jobReference": {
            ?"location": state.?location
          }
        }.encode_json()
      ).do_request().as(resp, resp.StatusCode == 200 ?
        resp.Body.decode_json().as(body,
          has(body.jobReference) ?
            {
              "next": {"job_id": string(body.jobReference.jobId)},
              "expires": now + duration(state.job_status_timeout),
            }
          :
            {}
        )
      :
        {
          "events": {
            "error": {
              "code": string(resp.StatusCode),
              "id": string(resp.Status),
              "message": "POST " + state.url.trim_right("/") + "/bigquery/v2/projects/" + state.project_id + "/jobs: " + (
                size(resp.Body) != 0 ?
                  string(resp.Body)
                :
                  string(resp.Status) + ' (' + string(resp.StatusCode) + ')'
              ),
            },
          },
          "want_more": false,
        }
      )
  )).as(state, state.with(
    // Check job status before fetching results
    state.?next.job_id.hasValue() && state.next.?job_status.orValue("") != "DONE" ?
      request(
        "GET",
        state.url.trim_right("/") + "/bigquery/v2/projects/" + state.project_id + "/jobs/" + state.next.job_id + "?" + {
          ?"location": state.?location.optMap(v, [v]),
        }.format_query()
      ).do_request().as(status_resp, status_resp.StatusCode == 200 ?
        status_resp.Body.decode_json().as(status_body, 
          has(status_body.status) && status_body.status.state == "DONE" ?
            // If job is done, continue to next step
            {
              "next": {
                "job_status": status_body.status.state,
                "job_id": state.next.job_id,
              }
            }
          :
            // If job has errors
            has(status_body.status) && has(status_body.status.errorResult) ?
              {
                "events": {
                  "error": {
                    "code": string(status_body.status.errorResult.reason),
                    "id": string(status_body.Status),
                    "message": "GET " + state.url.trim_right("/") + "/bigquery/v2/projects/" + state.project_id + "/jobs/" + state.next.job_id + ": " + string(status_body.status.errorResult.message),
                  }
                },
                "want_more": false,
                "next": {},
              }
            :
              // Job is still running
              {
                "next": {
                  "job_status": "RUNNING",
                  "job_id": state.next.job_id,
                },
                "want_more": string(now) <= string(state.expires),
                "events": [{"message":"retry"}],
              }
        )
      :
        {
          "events": {
            "error": {
              "code": string(status_resp.StatusCode),
              "id": string(status_resp.Status),
              "message": "GET " + state.url.trim_right("/") + "/bigquery/v2/projects/" + state.project_id + "/jobs/" + state.next.job_id + ": " + (
                size(status_resp.Body) != 0 ?
                  string(status_resp.Body)
                :
                  string(status_resp.Status) + ' (' + string(status_resp.StatusCode) + ')'
              ),
            },
          },
          "want_more": false,
          "next": {},
        }
      )
    :
      state
  )).as(state, state.with(
    // Cancel job if expired
    state.?next.job_id.hasValue() && state.next.?job_status.orValue("") != "DONE" && (string(now) > string(state.expires)) ?
      request(
        "POST",
        state.url.trim_right("/") + "/bigquery/v2/projects/" + state.project_id + "/jobs/" + state.next.job_id + "/cancel" + "?" + {
          ?"location": state.?location.optMap(v, [v]),
        }.format_query()
      ).do_request().as(status_resp, status_resp.StatusCode == 200 ?
        status_resp.Body.decode_json().as(status_body, {
          "next": {},
          "want_more": false,
        })
      :
        {
          "events": {
            "error": {
              "code": string(status_resp.StatusCode),
              "id": string(status_resp.Status),
              "message": "POST " + state.url.trim_right("/") + "/v2/projects/" + state.project_id + "/jobs/" + state.next.job_id + "/cancel" + ": " + (
                size(status_resp.Body) != 0 ?
                  string(status_resp.Body)
                :
                  string(status_resp.Status) + ' (' + string(status_resp.StatusCode) + ')'
              ),
            },
          },
          "want_more": false,
          "next": {},
        }
      )
    :
      state
  )).as(state, state.with(
    // Only proceed to fetch results if we have a job ID and the job is done
    state.?next.job_id.hasValue() && state.next.?job_status.orValue("") == "DONE" ?
      request(
        "GET",
        state.url.trim_right("/") + "/bigquery/v2/projects/"+ state.project_id +"/queries/" + state.next.job_id + "?" + {
          "maxResults": [string(state.batch_size)],
          ?"pageToken": state.?next.page_token.optMap(v, [v]),
          ?"location": state.?location.optMap(v, [v]),
        }.format_query()
      ).do_request().as(resp, resp.StatusCode == 200 ?
        resp.Body.decode_json().as(body, {
          "events": (
            has(body.schema) && has(body.rows) ?
              body.rows.map(row,{
                "message": ({"row": row, "schema": body.schema}).encode_json(),
              })
            :
              []
          ),
          "cursor": {
            ?"last_timestamp": has(body.schema) && has(body.rows) && body.rows.size() > 0 ?
              // extracting timestamp of the last event from the event_info object.
              body.collate("schema.fields.name").zip(body.rows[body.rows.size()-1].f).as(last_event,
                has(last_event.time_usec) ?
                  (
                    (
                      has(state.?cursor.last_timestamp) &&
                      last_event.time_usec.v < state.cursor.last_timestamp
                    ) ?
                      optional.of(state.cursor.last_timestamp)
                    :
                      optional.of(last_event.time_usec.v)
                  )
                :
                  state.?cursor.last_timestamp
              )
            :
              state.?cursor.last_timestamp
          },
          "next": {
            ?"page_token": body.?pageToken,
            // reset job ID if its last page.
            ?"job_id": has(body.pageToken) ? optional.of(state.next.job_id) : optional.none(),
            ?"job_status": state.next.?job_status,
          },
          "want_more": has(body.pageToken),
        })
      :
        {
          "events": {
            "error": {
              "code": string(resp.StatusCode),
              "id": string(resp.Status),
              "message": "GET " + state.url.trim_right("/") + "/bigquery/v2/projects/"+ state.project_id +"/queries/" + state.next.job_id + ": " + (
                size(resp.Body) != 0 ?
                  string(resp.Body)
                :
                  string(resp.Status) + ' (' + string(resp.StatusCode) + ')'
              ),
            },
          },
          "want_more": false,
          "next": {},
        }
      )
    :
      state
  ))
tags:
{{#if preserve_original_event}}
  - preserve_original_event
{{/if}}
{{#if preserve_duplicate_custom_fields}}
  - preserve_duplicate_custom_fields
{{/if}}
{{#each tags as |tag|}}
  - {{tag}}
{{/each}}
{{#contains "forwarded" tags}}
publisher_pipeline.disable_host: true
{{/contains}}
{{#if processors}}
processors:
{{processors}}
{{/if}}
