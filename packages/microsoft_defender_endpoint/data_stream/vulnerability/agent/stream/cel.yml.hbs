config_version: 2
interval: {{interval}}
resource.tracer:
  enabled: {{enable_request_tracer}}
  filename: "../../logs/cel/http-request-trace-*.ndjson"
  maxbackups: 5
{{#if proxy_url}}
resource.proxy_url: {{proxy_url}}
{{/if}}
{{#if ssl}}
resource.ssl: {{ssl}}
{{/if}}
{{#if http_client_timeout}}
resource.timeout: {{http_client_timeout}}
{{/if}}
resource.url: {{url}}
state:
  sas_valid_hours: {{sas_valid_hours}}
  token_url: {{login_url}}/{{tenant_id}}/oauth2/v2.0/token
  client_id: {{client_id}}
  client_secret: {{client_secret}}
  token_scopes:
{{#each token_scopes as |token_scope|}}
    - {{token_scope}}
{{/each}}
{{#if oauth_endpoint_params}}
  oauth_endpoint_params: {{oauth_endpoint_params}}
{{/if}}
redact:
  fields:
    - client_id
    - client_secret
    - token.access_token
program: |-
  state.with(
    state.?work_list.orValue([]).size() > 0 ?
      request(
        "GET", 
        state.work_list[0]
      ).do_request().as(resp, resp.StatusCode == 200 ?
        try(resp.Body.mime("application/gzip").decode_json_stream(), "decode_error").as(decoded_body,
          // 200 but decode error possible due to expired URLs. 
          // Error message should contain the resolution i.e., to increase the 'SAS Valid Hours' parameter.
          type(decoded_body) == map && has(decoded_body.decode_error) ?
            {
              "events": {
                "error": {
                  "code": string(resp.StatusCode),
                  "id": string(resp.Status),
                  "message": decoded_body.decode_error + ": Download URLs are likely expired.Try increasing the 'SAS Valid Hours' parameter to download more data.",
                },
              },
              // Empty the work_list as URLs are expired.
              "work_list": [],
              "want_more": false,
            }
          :
            decoded_body.map(v,
              {"message": dyn(v.encode_json())}
            ).as(events, {
              "events": events,
              // Keep polling if more work.
              "want_more": state.work_list.size() > 1,
              "work_list": tail(state.work_list),
            })
        )
      :
        // Check if 403 happened because download URL signatures are not valid anymore.
        resp.StatusCode == 403 && resp.Body.as(body, 
          string(body).contains_substr("Signature not valid in the specified key time frame")
        ) ?
          {
              "events": {
                "error": {
                  "code": string(resp.StatusCode),
                  "id": string(resp.Status),
                  "message": "Cannot fetch more data as signatures are not valid anymore. Try increasing the 'SAS Valid Hours' parameter to download more data.",
                },
              },
              // Empty the work_list as signatures are not valid anymore.
              "work_list": [],
              "want_more": false,
            }
      :
        // Ignore remaining work_list and return error.
        {
          "events": {
            "error": {
              "code": string(resp.StatusCode),
              "id": string(resp.Status),
              "message": "GET "+ state.work_list[0] + ":" + (
                size(resp.Body) != 0 ?
                  string(resp.Body)
                :
                  string(resp.Status) + ' (' + string(resp.StatusCode) + ')'
              ),
            },
          },
          "work_list": [], // Empty the work_list as URLs will likely be expired before polling again.
          "want_more": false,
        }
      )
    :
      // Periodic poll. No work_list, so get new token and work_list.
      (
        has(state.oauth_endpoint_params) && size(state.oauth_endpoint_params) > 0 ?
          {
            "client_id": [state.client_id],
            "client_secret": [state.client_secret],
            "scope": state.token_scopes,
          }.with(
            !("grant_type" in state.oauth_endpoint_params) ?
              {"grant_type": ["client_credentials"]}
            :
              {}
          ).with(zip(
            state.oauth_endpoint_params.keys(),
            state.oauth_endpoint_params.keys().map(k,
              type(state.oauth_endpoint_params[k]) == list ?
                state.oauth_endpoint_params[k]
              :
                [state.oauth_endpoint_params[k]]
            )
          ))
        :
          {
            "grant_type": ["client_credentials"],
            "client_id": [state.client_id],
            "client_secret": [state.client_secret],
            "scope": state.token_scopes,
          }
      ).as(params,
        post_request(state.token_url.trim_right("/"), "application/x-www-form-urlencoded",
          params.format_query()
        ).do_request().as(auth, auth.StatusCode == 200 ?
        auth.Body.decode_json()
      :
        {
          "events": {
            "error": {
              "code": string(auth.StatusCode),
              "id": string(auth.Status),
              "message": "POST /oauth2/v2.0/token :" +(
                size(auth.Body) != 0 ?
                  string(auth.Body)
                :
                  string(auth.Status) + ' (' + string(auth.StatusCode) + ')'
              ),
            },
          },
          "want_more": false,
        }
      ).as(token, !has(token.access_token) ? token :
        request(
          "GET",
          state.url.trim_right("/") + "/api/machines/SoftwareVulnerabilitiesExport?" + {
            "sasValidHours": [string(duration(state.sas_valid_hours).getHours())],
          }.format_query()
        ).with({
          "Header":{
            "Authorization": ["Bearer " + string(token.access_token)],
          }
        }).do_request().as(resp, resp.StatusCode == 200 ?
          resp.Body.decode_json().as(exportBody, exportBody.?exportFiles.orValue([]).size() == 0 ?
            // Nothing to download. Don't poll again.
            {
              "events": [],
              "want_more": false,
            }
          :
            // Return new work_list to download.
            {
              "events": [{"message":"retry"}],
              "work_list": exportBody.exportFiles,
              "want_more": true,
            }
          )
        :
          {
            "events": {
              "error": {
                "code": string(resp.StatusCode),
                "id": string(resp.Status),
                "message": "GET /api/machines/SoftwareVulnerabilitiesExport :" + (
                  size(resp.Body) != 0 ?
                    string(resp.Body)
                  :
                    string(resp.Status) + ' (' + string(resp.StatusCode) + ')'
                ),
              },
            },
            "want_more": false,
          }
        )
      )
    )
  )
tags:
{{#if preserve_original_event}}
  - preserve_original_event
{{/if}}
{{#if preserve_duplicate_custom_fields}}
  - preserve_duplicate_custom_fields
{{/if}}
{{#each tags as |tag|}}
  - {{tag}}
{{/each}}
{{#contains "forwarded" tags}}
publisher_pipeline.disable_host: true
{{/contains}}
{{#if processors}}
processors:
{{processors}}
{{/if}}
