config_version: 2
interval: {{interval}}
resource.tracer:
  enabled: {{enable_request_tracer}}
  filename: "../../logs/cel/http-request-trace-*.ndjson"
  maxbackups: 5
{{#if proxy_url}}
resource.proxy_url: {{proxy_url}}
{{/if}}
{{#if ssl}}
resource.ssl: {{ssl}}
{{/if}}
{{#if http_client_timeout}}
resource.timeout: {{http_client_timeout}}
{{/if}}
resource.url: {{url}}
auth.oauth2:
  provider: azure
  client.id: {{client_id}}
  client.secret: {{client_secret}}
  scopes:
{{#each token_scopes as |token_scope|}}
    - {{token_scope}}
{{/each}}
{{#if login_url}}
  token_url: {{login_url}}/{{tenant_id}}/oauth2/v2.0/token
{{else if tenant_id}}
  azure.tenant_id: {{tenant_id}}
{{/if}}

state:
  sas_valid_hours: {{sas_valid_hours}}
redact:
  fields: ~
program: |-
  state.with(
    state.?work_list.orValue([]).size() > 0 ?
      request(
        "GET", 
        state.?work_list[0]
      ).do_request().as(resp, resp.StatusCode == 200 ?
        resp.Body.mime("application/gzip").File.as(file, file.size() > 0 ?
          file[0].Data.as(data, bytes(data).decode_json().as(body, {
            "events": body.map(v,
              {
                "message": v.encode_json(),
              }
            ),
          }))
        :
          // Safe gaurd if file is empty. Don't publish events and continue.
          {
            "events": [],
          }
        ).as(events, events.with({
            "work_list": tail(state.work_list),
          })).as(s, s.with({
            // Keep polling if more work.
            "want_more": s.work_list.size() > 0,
          }))
      :
        // It is possible that download URLs have expired, so ignore remaining work_list and return error.
        {
          "events": {
            "error": {
              "code": string(resp.StatusCode),
              "id": string(resp.Status),
              "message": "GET "+ state.url.trim_right("/") + ":" + (
                size(resp.Body) != 0 ?
                  string(resp.Body)
                :
                  string(resp.Status) + ' (' + string(resp.StatusCode) + ')'
              ),
            },
          },
          "want_more": false,
        }
      )
    :
      // Periodic poll. No work_list, so get new work_list.
      request(
        "GET",
        state.url.trim_right("/") + "/api/machines/SoftwareVulnerabilitiesExport" + {
          "sasValidHours": [string(state.sas_valid_hours)],
        }.format_query()
      ).do_request().as(resp, resp.StatusCode == 200 ?
        resp.Body.decode_json().as(exportBody, exportBody.?exportFiles.orValue([]).size() == 0 ?
          // Nothing to download. Don't poll again.
          {
            "want_more": false,
          }
        :
          // Return new work_list to download.
          {
            "work_list": exportBody.exportFiles,
            "want_more": true,
          }
        )
      :
        {
          "events": {
            "error": {
              "code": string(resp.StatusCode),
              "id": string(resp.Status),
              "message": "GET "+ state.url.trim_right("/") + ":" + (
                size(resp.Body) != 0 ?
                  string(resp.Body)
                :
                  string(resp.Status) + ' (' + string(resp.StatusCode) + ')'
              ),
            },
          },
          "want_more": false,
        }
      )
  )
tags:
{{#if preserve_original_event}}
  - preserve_original_event
{{/if}}
{{#if preserve_duplicate_custom_fields}}
  - preserve_duplicate_custom_fields
{{/if}}
{{#each tags as |tag|}}
  - {{tag}}
{{/each}}
{{#contains "forwarded" tags}}
publisher_pipeline.disable_host: true
{{/contains}}
{{#if processors}}
processors:
{{processors}}
{{/if}}
