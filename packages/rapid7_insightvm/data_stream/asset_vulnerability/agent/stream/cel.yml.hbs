config_version: 2
interval: {{interval}}
resource.tracer:
  enabled: {{enable_request_tracer}}
  filename: "../../logs/cel/http-request-trace-*.ndjson"
  maxbackups: 5
{{#if proxy_url}}
resource.proxy_url: {{proxy_url}}
{{/if}}
{{#if ssl}}
resource.ssl: {{ssl}}
{{/if}}
{{#if http_client_timeout}}
resource.timeout: {{http_client_timeout}}
{{/if}}
resource.url: {{url}}
state:
  api_key: {{api_key}}
  batch_size: {{batch_size}}
  initial_interval: {{initial_interval}}
redact:
  fields:
    - api_key
program: |-

  // The program collects all assets and enriches them with vulnerability details.
  // Here's a detailed overview of how this process works:
  //
  // On execution, the program calls the [Assets API][1] and retrieves the first batch of assets.
  // From this batch, we extract all vulnerability IDs associated with the assets (including new, existing, and remediated vulnerabilities).
  // We then use this list of vulnerability IDs as a filter to call the [Vulnerabilities API][2],
  // retrieving all relevant vulnerabilities until we receive a null value for the next cursor.
  //
  // After retrieving the vulnerability data, we aggregate it with the corresponding assets and publish the events.
  // This process continues batch by batch until the Assets API returns a null value for the next cursor.
  //
  // [1]: https://help.rapid7.com/insightvm/en-us/api/integrations.html#tag/Asset/operation/searchIntegrationAssets
  // [2]: https://help.rapid7.com/insightvm/en-us/api/integrations.html#tag/Vulnerability/operation/searchIntegrationVulnerabilities

  (
    state.?want_more.orValue(false) ?
      state.interval_time
    :
      now
  ).as(interval_time,
    // If assets are already present and the vulnerabilities for the current asset batch have not been fully fetched,
    // skip the Asset API call and continue forwarding the state to the next block.
    has(state.assets) && (state.is_all_assets_fetched || !state.?is_current_vulnerabilities_fetched.orValue(false)) ?
      {
        "assets": state.assets,
        "is_all_assets_fetched": state.is_all_assets_fetched,
        "asset_vuln_ids": state.asset_vuln_ids,
        "interval_time": interval_time,
        ?"next_asset_cursor": state.?next_asset_cursor,
      }
    :
      // The `includeSame` query parameter and `last_scan_end` body filter are only added in the first execution of program.
      // These parameters are used to collect historical vulnerabilities for the assets.
      request(
        "POST",
        state.url.trim_right("/") + "/vm/v4/integration/assets?" + {
          "size": [string(state.batch_size)],
          "includeUniqueIdentifiers": ["true"],
          ?"includeSame": has(state.?cursor.last_interval_time) ? optional.none() : optional.of(["true"]),
          ?"comparisonTime": state.?cursor.last_interval_time.optMap(v, [v]),
          ?"cursor": state.?next_asset_cursor.optMap(v, [v]),
        }.format_query()
      ).with({
        "Header": {
          "X-Api-Key": [state.api_key],
          "Content-Type": ["application/json"],
        },
        "Body": {
          ?"asset": has(state.?cursor.last_interval_time) ?
            optional.none()
          :
            optional.of(("last_scan_end > " + (timestamp(interval_time) - duration(state.initial_interval)).format(time_layout.RFC3339))),
        }.encode_json(),
      }).do_request().as(resp, resp.StatusCode == 200 ?
        resp.Body.decode_json().as(body, {
          "events": [{"message": "retry"}],
          "batch_size": state.batch_size,
          "initial_interval": state.initial_interval,
          "api_key": state.api_key,
          "cursor": {
            ?"last_interval_time": state.?cursor.last_interval_time,
          },
          ?"next_asset_cursor": has(body.?metadata.cursor) && body.metadata.cursor != null ? optional.of(body.metadata.cursor) : optional.none(),
          "is_all_assets_fetched": !has(body.metadata.cursor) || body.metadata.cursor == null,
          "assets": body.data,
          "asset_vuln_ids": body.data.map(a, (
            a.?same.orValue([]).map(s, s.vulnerability_id) +
            a.?new.orValue([]).map(n, n.vulnerability_id) +
            a.?remediated.orValue([]).map(r, r.vulnerability_id)
          )).flatten().as(vuln_ids,
            zip(vuln_ids, vuln_ids) // to get a unique set of IDs
          ).keys(),
          "interval_time": interval_time,
          "want_more": true
        })
      :
        {
          "events": {
            "error": {
              "code": string(resp.StatusCode),
              "id": string(resp.Status),
              "message": "POST " + state.url.trim_right("/") + "/vm/v4/integration/assets:" + (
                size(resp.Body) != 0 ?
                  string(resp.Body)
                :
                  string(resp.Status) + ' (' + string(resp.StatusCode) + ')'
              ),
            },
          },
          "want_more": false,
          "api_key": state.api_key,
          "batch_size": state.batch_size,
          "initial_interval": state.initial_interval,
        }
      )
  ).as(work,
    has(work.events) ? work : // Exit early
      (
        // If the current set of vulnerabilities has been fetched, skip the Vulnerability API call and continue forwarding the state to the next block.
        (has(state.vulnerabilities) && state.is_current_vulnerabilities_fetched) ?
          work.with({
            "vulnerabilities": state.vulnerabilities,
            "is_current_vulnerabilities_fetched": state.is_current_vulnerabilities_fetched
          })
        :
          request(
            "POST",
            state.url.trim_right("/") + "/vm/v4/integration/vulnerabilities?" + {
              "size": ["500"],
              ?"cursor": state.?next_vuln_cursor.optMap(v, [v]),
            }.format_query()
          ).with({
            "Header": {
              "X-Api-Key": [state.api_key],
              "Content-Type": ["application/json"]
            },
            "Body": {
              "vulnerability": work.asset_vuln_ids.as(x, sprintf("id IN ['%s']", [x.join("','")])),
            }.encode_json(),
          }).do_request().as(resp, resp.StatusCode == 200 ?
            resp.Body.decode_json().as(body, {
              "events": [{"message": "retry"}],
              "batch_size": state.batch_size,
              "api_key": state.api_key,
              "initial_interval": state.initial_interval,
              "assets": state.assets,
              "cursor": {
                ?"last_interval_time": state.?cursor.last_interval_time,
              },
              "is_all_assets_fetched": state.is_all_assets_fetched,
              ?"next_vuln_cursor": has(body.?metadata.cursor) && body.metadata.cursor != null ? optional.of(body.metadata.cursor) : optional.none(),
              ?"next_asset_cursor": work.?next_asset_cursor,
              "is_current_vulnerabilities_fetched": !has(body.metadata.cursor) || body.metadata.cursor == null,
              "vulnerabilities": (state.?vulnerabilities.orValue([]) + body.data).flatten(),
              "asset_vuln_ids": work.asset_vuln_ids,
              "interval_time": work.interval_time,
              "want_more": true
            })
          :
            {
              "events": {
                "error": {
                  "code": string(resp.StatusCode),
                  "id": string(resp.Status),
                  "message": "POST " + state.url.trim_right("/") + "/vm/v4/integration/vulnerabilities:" + (
                    size(resp.Body) != 0 ?
                      string(resp.Body)
                    :
                      string(resp.Status) + ' (' + string(resp.StatusCode) + ')'
                  ),
                },
              },
              "want_more": false,
              "api_key": state.api_key,
              "batch_size": state.batch_size,
              "initial_interval": state.initial_interval,
            }
          )
      )
  ).as(work,
    (type(work.events) == map || !(work.is_all_assets_fetched || work.?is_current_vulnerabilities_fetched.orValue(false))) ?
      work // Error or more vulnerabilities to fetch for current assets.
    :
      work.is_all_assets_fetched ?
        // All assets fetched. Save cursor and end iteration.
        {
          "events": [],
          "cursor": {
            ?"last_interval_time": optional.of(work.interval_time),
          },
          "want_more": false,
          "api_key": state.api_key,
          "batch_size": state.batch_size,
          "initial_interval": state.initial_interval,
        }
      :
        // All vulnerabilities of current assets batch are fetched. Aggregate and publish events.
        work.with({
          // convert vulnerabilities to map for better searching
          "vulnerabilities": work.vulnerabilities.map(e, {
            "key": e.id,
            "value": e
          }).as(result, zip(
            result.map(e, e.key),
            result.map(e, e.value)
          )),
          // combine same[] new[] remediated[] into vulnerability[]
          "assets": work.assets.map(e, e.with({
            "vulnerabilities": e.?same.orValue([]) + e.?new.orValue([]) + e.?remediated.orValue([]).map(r, r.with({"is_remediated": true})),
          }).drop(["new","remediated","same"]))
        }).as(work, {
          "events": (work.assets.map(e, e.vulnerabilities.map(v, {
            "message": e.with({"vulnerability": v.with(
              work.?vulnerabilities[v.vulnerability_id].orValue("not present") != "not present" ?
                work.vulnerabilities[v.vulnerability_id]
              :
                {"is_enriched": false}
            )}).drop("vulnerabilities").encode_json()
          })).flatten()).as(result, size(result) != 0 ? // it will be empty when there is no vulnerability for current assets batch
            result
          :
            [{"message": "retry"}] // retry execution as is_all_assets_fetched is false
          ),
          "cursor": {
            ?"last_interval_time": state.?cursor.last_interval_time,
          },
          "is_all_assets_fetched": work.is_all_assets_fetched,
          "is_current_vulnerabilities_fetched": work.is_current_vulnerabilities_fetched,
          ?"next_asset_cursor": work.?next_asset_cursor,
          "interval_time": work.interval_time,
          "want_more": true,
          "api_key": state.api_key,
          "batch_size": state.batch_size,
          "initial_interval": state.initial_interval,
        })
  )
tags:
{{#if preserve_original_event}}
  - preserve_original_event
{{/if}}
{{#if preserve_duplicate_custom_fields}}
  - preserve_duplicate_custom_fields
{{/if}}
{{#each tags as |tag|}}
  - {{tag}}
{{/each}}
{{#contains "forwarded" tags}}
publisher_pipeline.disable_host: true
{{/contains}}
processors:
- drop_event:
    when:
      equals:
        message: retry
{{#if processors}}
{{processors}}
{{/if}}
