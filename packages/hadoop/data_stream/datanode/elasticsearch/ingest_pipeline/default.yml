---
description: Pipeline for parsing Hadoop Datanode metrics
processors:
  - set:
      field: ecs.version
      value: '8.11.0'
  - set:
      field: event.type
      value: [info]
  - set:
      field: event.kind
      value: metric
  - set:
      field: event.category
      value: [database]
  - rename:
      field: http
      target_field: hadoop
      ignore_missing: true
      ignore_failure: true
  - script:
      source: >
        ctx.hadoop.datanode.temp = ctx.hadoop.datanode.beans[0];
        ctx.hadoop.datanode.remove("beans")
  - pipeline:
      if: ctx.hadoop.datanode.temp["tag.Context"] == 'FSDatasetState'
      name: '{{ IngestPipeline "pipeline-dataset" }}' 
  - pipeline:
      if: ctx.hadoop.datanode.temp["tag.Context"] == 'dfs'
      name: '{{ IngestPipeline "pipeline-dfs" }}' 
  - remove:
      field:
        - hadoop.datanode.temp
      ignore_missing: true
      ignore_failure: true
  - script:
      description: Drops null/empty values recursively
      lang: painless
      source: |
        boolean drop(Object o) {
          if (o == null || o == "") {
            return true;
          } else if (o instanceof Map) {
            ((Map) o).values().removeIf(v -> drop(v));
            return (((Map) o).size() == 0);
          } else if (o instanceof List) {
            ((List) o).removeIf(v -> drop(v));
            return (((List) o).length == 0);
          }
          return false;
        }
        drop(ctx);
on_failure:
  - set:
      field: error.message
      value: "{{{_ingest.on_failure_message}}}"
