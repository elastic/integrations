# Faitour

This integration is for [Faitour](https://github.com/MakoWish/Faitour) honeypot event logs. The package processes messages from Faitour honeypot logs to allow visibility and alerting to observed activity on your network.

## Data streams

The Faitour integration collects the following event types:

- **events**

Elastic Agent must be installed. For more details, check the Elastic Agent [installation instructions](docs-content://reference/fleet/install-elastic-agents.md).


### Enabling the integration in Elastic:

1. In Kibana navigate to Management > Integrations.
2. In "Search for integrations" top bar, search for `Faitour`.
3. Select the "Faitour" integration from the search results.
4. Select "Add Faitour" to add the integration.
5. Add all the required integration configuration parameters.
6. Select "Save and continue" to save the integration.

## Logs

### Faitour Honeypot

The `honeypot` dataset collects the Faitour honeypot logs.

An example event for `honeypot` looks as following:

```json
{
    "@timestamp": "2025-02-05T18:00:04.944Z",
    "event": {
        "action": "check_auth_password",
        "category": [
            "network",
            "authentication",
            "intrusion_detection"
        ],
        "dataset": "faitour.honeypot",
        "ingested": "2025-02-05T19:05:36.900080752Z",
        "kind": "alert",
        "original": "{\"timestamp\":\"2025-02-05T18:00:04.944\",\"log\":{\"level\":\"INFO\",\"logger\":\"faitour\",\"origin\":{\"file\":{\"line\":28,\"name\":\"/home/foo/Faitour/emulators/ssh.py\"}}},\"event\":{\"provider\":\"ssh\",\"type\":[\"connection\",\"allowed\",\"start\"],\"kind\":\"alert\",\"category\":[\"network\",\"authentication\",\"intrusion_detection\"],\"dataset\":\"faitour.honeypot\",\"action\":\"check_auth_password\",\"reason\":\"SSH authentication successful\",\"outcome\":\"success\"},\"user\":{\"name\":\"admin\",\"password\":\"<REDACTED>\"}}",
        "outcome": "success",
        "provider": "ssh",
        "reason": "SSH authentication successful",
        "type": [
            "connection",
            "allowed",
            "start"
        ]
    },
    "faitour": {},
    "log": {
        "level": "INFO",
        "logger": "faitour",
        "origin": {
            "file": {
                "line": 28,
                "name": "/home/foo/Faitour/emulators/ssh.py"
            }
        }
    },
    "tags": [
        "preserve_original_event",
        "redact_passwords"
    ],
    "user": {
        "name": "admin"
    }
}
```

**Exported fields**

| Field | Description | Type |
|---|---|---|
| @timestamp | Date/time when the event originated. This is the date/time extracted from the event, typically representing when the event was generated by the source. If the event source has no original timestamp, this value is typically populated by the first time the event was received by the pipeline. Required field for all events. | date |
| cloud.image.id | Image ID for the cloud instance. | keyword |
| data_stream.dataset | Data stream dataset. | constant_keyword |
| data_stream.namespace | Data stream namespace. | constant_keyword |
| data_stream.type | Data stream type. | constant_keyword |
| event.dataset | Event dataset | constant_keyword |
| event.module | Event module | constant_keyword |
| host.containerized | If the host is a container. | boolean |
| host.os.build | OS build information. | keyword |
| host.os.codename | OS codename, if any. | keyword |
| input.type | Input type. | keyword |
| log.offset | Offset of the entry in the log file. | long |
| user.password | User password field for non-redacted events. | keyword |


### Faitour Application

The `application` dataset collects the Faitour application logs.

An example event for `application` looks as following:

```json
{
    "@timestamp": "2025-02-05T19:30:39.315Z",
    "log": {
        "level": "DEBUG",
        "logger": "faitour",
        "origin": {
            "file": {
                "name": "/home/foo/Faitour/emulators/http.py",
                "line": 271
            }
        }
    },
    "faitour": {},
    "event": {
        "reason": "HTTP certificate and key already exist",
        "ingested": "2025-02-07T04:18:44.319671658Z",
        "original": "{\"timestamp\":\"2025-02-05T19:30:39.315\",\"log\":{\"level\":\"DEBUG\",\"logger\":\"faitour\",\"origin\":{\"file\":{\"line\":271,\"name\":\"/home/foo/Faitour/emulators/http.py\"}}},\"event\":{\"provider\":\"http\",\"type\":[\"info\"],\"kind\":\"event\",\"category\":[\"configuration\"],\"dataset\":\"faitour.application\",\"action\":\"generate_self_signed_cert\",\"reason\":\"HTTP certificate and key already exist\",\"outcome\":\"success\"}}",
        "provider": "http",
        "kind": "event",
        "action": "generate_self_signed_cert",
        "type": [
            "info"
        ],
        "category": [
            "configuration"
        ],
        "dataset": "faitour.application",
        "outcome": "success"
    },
    "tags": [
        "redact_passwords",
        "preserve_original_event"
    ]
}
```

**Exported fields**

| Field | Description | Type |
|---|---|---|
| @timestamp | Date/time when the event originated. This is the date/time extracted from the event, typically representing when the event was generated by the source. If the event source has no original timestamp, this value is typically populated by the first time the event was received by the pipeline. Required field for all events. | date |
| cloud.image.id | Image ID for the cloud instance. | keyword |
| data_stream.dataset | Data stream dataset. | constant_keyword |
| data_stream.namespace | Data stream namespace. | constant_keyword |
| data_stream.type | Data stream type. | constant_keyword |
| event.dataset | Event dataset | constant_keyword |
| event.module | Event module | constant_keyword |
| host.containerized | If the host is a container. | boolean |
| host.os.build | OS build information. | keyword |
| host.os.codename | OS codename, if any. | keyword |
| input.type | Input type. | keyword |
| log.offset | Offset of the entry in the log file. | long |

