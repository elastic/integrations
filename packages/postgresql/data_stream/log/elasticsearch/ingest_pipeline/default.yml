---
description: Pipeline for parsing PostgreSQL logs.
processors:
  - set:
      field: event.ingested
      value: '{{_ingest.timestamp}}'
  - set:
      field: ecs.version
      value: '8.11.0'
  - rename:
      field: message
      target_field: event.original
      ignore_missing: true
      if: 'ctx.event?.original == null'
  - grok:
      field: event.original
      patterns:
      - '^%{DATETIME:postgresql.log.timestamp}%{CHAR:separator}%{GREEDYDATA:raw_message}'
      pattern_definitions:
        PG_DATETIME: '%{YEAR}-%{MONTHNUM}-%{MONTHDAY}[T ]%{ISO8601_HOUR}:?%{MINUTE}(?::?%{SECOND})'
        POSTGRES_TZ: '([a-zA-Z]{1,4})|(?:Z|[+-]%{HOUR}(?::?%{MINUTE})?)'
        DATETIME: '%{PG_DATETIME:_temp_.timestamp} %{POSTGRES_TZ:event.timezone}'
        CHAR: .
        GREEDYDATA: |-
          (.|
          |	)*
  - script:
      lang: painless
      tag: script_timezone
      description: >-
        Add support to map timezone abbreviations that are not supported by
        Java manually. If no match is found, it will default to
        UTC as before.
      if: ctx._temp_?.timestamp != null
      source: |-
        String get_timezone(def ctx) {
          if (ctx.event?.timezone != null) {
            String tz = ctx.event.timezone.trim().toUpperCase();

            // Handle abbreviations (e.g., CEST, EST)
            if (tz.length() <= 4) {
              return tz;
            }

            // Handle offset formats (+00:00, -00:00, +00, -00)
            if (tz.startsWith('+') || tz.startsWith('-')) {
              return tz.length() == 3 ? "UTC" + tz + ":00" : "UTC" + tz;
            }

            return tz;
          }

          ctx.event.timezone = 'UTC';
          return 'UTC';
        }

        def event_timezone = get_timezone(ctx);
        boolean isAbbreviation = !(event_timezone.contains('+') || event_timezone.contains('-') || event_timezone.length() > 4);

        if (isAbbreviation) {
          Map CUSTOM_ZONE_IDS = new HashMap(ZoneId.SHORT_IDS);
          CUSTOM_ZONE_IDS.put("CEST", "Europe/Paris");
          CUSTOM_ZONE_IDS.put("CET", "Europe/Paris");
          CUSTOM_ZONE_IDS.put("BST", "Europe/London");
          CUSTOM_ZONE_IDS.put("IST", "Asia/Kolkata");
          CUSTOM_ZONE_IDS.put("EEST", "Europe/Athens");
          CUSTOM_ZONE_IDS.put("EET", "Europe/Athens");
          CUSTOM_ZONE_IDS.put("AEST", "Australia/Sydney");
          CUSTOM_ZONE_IDS.put("AEDT", "Australia/Sydney");
          CUSTOM_ZONE_IDS.put("ACST", "Australia/Adelaide");
          CUSTOM_ZONE_IDS.put("ACDT", "Australia/Adelaide");
          CUSTOM_ZONE_IDS.put("AWST", "Australia/Perth");

          // Timezone abbreviation (e.g., CEST) needs to be put inside the timestamp
          ZoneId zoneId = ZoneId.of(event_timezone, CUSTOM_ZONE_IDS);
          ctx._temp_.date_timezone = zoneId.getId();
          ctx?._temp_.timestamp += " " + event_timezone;
        } else {
          // Timezone is either abbreviation+-offset (e.g., UTC+1) or long representation (e.g., Europe/Athens)
          ctx._temp_.date_timezone = event_timezone;
        }

  - pipeline:
      name: '{{ IngestPipeline "pipeline-log" }}'
      if: ctx.separator != ',' && ctx.separator != ':'
  - pipeline:
      name: '{{ IngestPipeline "pipeline-csv" }}'
      if: ctx.separator == ','
  - pipeline:
      name: '{{ IngestPipeline "pipeline-aws-log" }}'
      if: ctx.separator == ':'
  - date:
      field: _temp_.timestamp
      target_field: '@timestamp'
      timezone: '{{{_temp_.date_timezone}}}'
      formats:
      - yyyy-MM-dd HH:mm:ss.SSS zz
      - yyyy-MM-dd HH:mm:ss zz
      - yyyy-MM-dd HH:mm:ss.SSS
      - yyyy-MM-dd HH:mm:ss
      on_failure:
        - set:
            field: error.message
            value: '{{ _ingest.on_failure_message }}'
  - convert:
        field: postgresql.log.client_addr
        type: ip
        ignore_missing: true
        on_failure:
            - set:
                field: tmp_host
                copy_from: postgresql.log.client_addr
            - append:
                field: related.hosts
                value: '{{{tmp_host}}}'
                allow_duplicates: false
                if: "ctx.tmp_host != null"
            - set:
                field: tmp_host
                value: ""
                if: "ctx.tmp_host != null"
  - append:
      field: related.ip
      value: '{{{postgresql.log.client_addr}}}'
      allow_duplicates: false
      if: "ctx.tmp_host == null"
  - script:
      lang: painless
      source: ctx.event.duration = Math.round(ctx.temp.duration * params.scale)
      params:
        scale: 1000000
      if: ctx.temp?.duration != null
  - remove:
      field: temp.duration
      ignore_missing: true
  - set:
      field: event.kind
      value: event
  - append:
      field: event.category
      value:
        - database
  - set:
      field: event.type
      value:
        - info
      if: "ctx?.postgresql?.log?.sql_state_code == null || (ctx.postgresql.log.sql_state_code ==~ /^0[012].*/)"
  - set:
      field: event.type
      value:
        - error
      if: "ctx?.postgresql?.log?.sql_state_code != null && ! (ctx.postgresql.log.sql_state_code ==~ /^0[012].*/)"
  - append:
      field: related.user
      value: "{{user.name}}"
      if: "ctx?.user?.name != null"
  - remove:
      field:
        - separator
        - raw_message
  - remove:
      field: temp
      ignore_missing: true
  - remove:
      field: event.original
      if: "ctx?.tags == null || !(ctx.tags.contains('preserve_original_event'))"
      ignore_failure: true
      ignore_missing: true
  - remove:
      field: _temp_
      ignore_missing: true
  - script:
      lang: painless
      source: |-
        boolean drop(Object o) {
          if (o == null || o == '') {
            return true;
          } else if (o instanceof Map) {
            ((Map) o).values().removeIf(v -> drop(v));
            return (((Map) o).size() == 0);
          } else if (o instanceof List) {
            ((List) o).removeIf(v -> drop(v));
            return (((List) o).size() == 0);
          }
          return false;
        }
        drop(ctx);
      description: Drops null and empty values recursively from the Elasticsearch document context.
on_failure:
  - set:
      field: error.message
      value: '{{ _ingest.on_failure_message }}'
