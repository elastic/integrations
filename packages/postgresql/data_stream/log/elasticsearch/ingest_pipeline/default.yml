---
description: Pipeline for parsing PostgreSQL logs.
processors:
  - set:
      field: event.ingested
      value: '{{_ingest.timestamp}}'
  - set:
      field: ecs.version
      value: '8.11.0'
  - rename:
      field: message
      target_field: event.original
      ignore_missing: true
      if: 'ctx.event?.original == null'
  - grok:
      field: event.original
      patterns:
      - '^%{DATETIME:postgresql.log.timestamp}%{CHAR:separator}%{GREEDYDATA:raw_message}'
      pattern_definitions:
        PG_DATETIME: '%{YEAR}-%{MONTHNUM}-%{MONTHDAY}[T ]%{ISO8601_HOUR}:?%{MINUTE}(?::?%{SECOND})'
        POSTGRES_TZ: '([a-zA-Z]{1,4})|(?:Z|[+-]%{HOUR}(?::?%{MINUTE})?)'
        DATETIME: '%{PG_DATETIME:_temp_.timestamp} %{POSTGRES_TZ:event.timezone}'
        CHAR: .
        GREEDYDATA: |-
          (.|
          |	)*
  - script:
      lang: painless
      tag: script_timezone
      description: >-
        Add support to map timezone abbreviations that are not supported by
        Java manually. If no match is found from the user-specified list, 
        it will default to the value of event.timezone.
      if: ctx._temp_?.timestamp != null
      source: |-
        String get_timezone(def ctx) {
          if (ctx.event?.timezone != null) {
            if (ctx._conf?.tz_map != null) {
              for (def item : ctx._conf.tz_map) {
                if (item.tz_short == ctx.event?.timezone) {
                  return item.tz_long;
                }
              }
            }
            return ctx.event.timezone;
          }

          ctx.event.timezone = 'UTC';
          return 'UTC';
        }
        
        def event_timezone = get_timezone(ctx);
        if (!(event_timezone.contains('+')) && !(event_timezone.contains('-')) && !(event_timezone.length() > 4)) {
          // timezone abbreviation e.g. CEST need to be put inside the timestamp
          SimpleDateFormat sdf = new SimpleDateFormat("z");
          sdf.parse(event_timezone);
          ctx._temp_.date_timezone = ZoneId.of(sdf.getTimeZone().getID(), ZoneId.SHORT_IDS).getId();
          ctx?._temp_.timestamp = ctx?._temp_.timestamp + " " + event_timezone;
        } else {
          // timezone is either abbreviation+-offset e.g. UTC+1 or long representation
          // e.g. Europe/Athens needs to be put as a ZoneId and *not* inside the timestamp
          ctx._temp_.date_timezone = event_timezone;
        }

  - pipeline:
      name: '{{ IngestPipeline "pipeline-log" }}'
      if: ctx.separator != ',' && ctx.separator != ':'
  - pipeline:
      name: '{{ IngestPipeline "pipeline-csv" }}'
      if: ctx.separator == ','
  - pipeline:
      name: '{{ IngestPipeline "pipeline-aws-log" }}'
      if: ctx.separator == ':'
  - date:
      field: _temp_.timestamp
      target_field: '@timestamp'
      timezone: '{{{_temp_.date_timezone}}}'
      formats:
      - yyyy-MM-dd HH:mm:ss.SSS zz
      - yyyy-MM-dd HH:mm:ss zz
      - yyyy-MM-dd HH:mm:ss.SSS
      - yyyy-MM-dd HH:mm:ss
      on_failure:
        - set:
            field: error.message
            value: '{{ _ingest.on_failure_message }}'
  - convert:
        field: postgresql.log.client_addr
        type: ip
        ignore_missing: true
        on_failure:
            - set:
                field: tmp_host
                copy_from: postgresql.log.client_addr
            - append:
                field: related.hosts
                value: '{{{tmp_host}}}'
                allow_duplicates: false
                if: "ctx.tmp_host != null"
            - set:
                field: tmp_host
                value: ""
                if: "ctx.tmp_host != null"
  - append:
      field: related.ip
      value: '{{{postgresql.log.client_addr}}}'
      allow_duplicates: false
      if: "ctx.tmp_host == null"
  - script:
      lang: painless
      source: ctx.event.duration = Math.round(ctx.temp.duration * params.scale)
      params:
        scale: 1000000
      if: ctx.temp?.duration != null
  - remove:
      field: temp.duration
      ignore_missing: true
  - set:
      field: event.kind
      value: event
  - append:
      field: event.category
      value:
        - database
  - set:
      field: event.type
      value:
        - info
      if: "ctx?.postgresql?.log?.sql_state_code == null || (ctx.postgresql.log.sql_state_code ==~ /^0[012].*/)"
  - set:
      field: event.type
      value:
        - error
      if: "ctx?.postgresql?.log?.sql_state_code != null && ! (ctx.postgresql.log.sql_state_code ==~ /^0[012].*/)"
  - append:
      field: related.user
      value: "{{user.name}}"
      if: "ctx?.user?.name != null"
  - remove:
      field:
        - separator
        - raw_message
  - remove:
      field: temp
      ignore_missing: true
  - remove:
      field: event.original
      if: "ctx?.tags == null || !(ctx.tags.contains('preserve_original_event'))"
      ignore_failure: true
      ignore_missing: true
  - remove:
      field:
       - _temp_
       - _conf
      ignore_missing: true
  - script:
      lang: painless
      source: |-
        boolean drop(Object o) {
          if (o == null || o == '') {
            return true;
          } else if (o instanceof Map) {
            ((Map) o).values().removeIf(v -> drop(v));
            return (((Map) o).size() == 0);
          } else if (o instanceof List) {
            ((List) o).removeIf(v -> drop(v));
            return (((List) o).size() == 0);
          }
          return false;
        }
        drop(ctx);
      description: Drops null and empty values recursively from the Elasticsearch document context.
on_failure:
  - set:
      field: error.message
      value: '{{ _ingest.on_failure_message }}'
