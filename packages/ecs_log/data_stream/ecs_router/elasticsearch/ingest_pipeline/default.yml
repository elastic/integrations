---
processors:
- remove:
    description: |
      This data stream is meant for routing only, we want to avoid that data is written to it.
      We'll use the dataset that is specified in the ECS JSON log message, or use 'generic' as the default.
    field: data_stream.dataset
    ignore_missing: true
- remove:
    field: event.dataset
    ignore_missing: true
- pipeline:
    name: '{{ IngestPipeline "logs-ecs-json-pipeline" }}'
    if: |-
      def message = ctx.message;
      return message != null
        && message.startsWith('{')
        && message.endsWith('}')
        && message.contains('"@timestamp"')
- set:
    description: Uses event.dataset as a default for data_stream.dataset if the latter is not set.
    field: data_stream.dataset
    copy_from: event.dataset
    if: ctx.event?.dataset instanceof String && ctx.event.dataset.length() > 1
    override: false
- script:
    source: |
      ctx.data_stream.dataset = /[\/*?"<>|, #:-]/.matcher(ctx.data_stream.dataset).replaceAll('_')
    if: ctx.data_stream?.dataset != null
- script:
    source: |
      ctx.data_stream.namespace = /[\/*?"<>|, #:]/.matcher(ctx.data_stream.namespace).replaceAll('_')
    if: ctx.data_stream?.namespace != null
- set:
    field: data_stream.type
    value: logs
- set:
    field: data_stream.dataset
    value: generic
    override: false
- set:
    field: data_stream.namespace
    value: default
    override: false
- set:
    field: event.dataset
    copy_from: data_stream.dataset
- set:
    field: _index
    value: logs-{{{data_stream.dataset}}}-{{{data_stream.namespace}}}
