description: Aggregates daily total ECU usage per tier and datastream from billing metrics, using ingested timestamps with a 1-hour sync delay and running every 60 minutes.
source:
  index:
    - chargeback-monitoring-read # Set this before running the transform. Either to `monitoring-indices` or `metrics-elasticsearch.stack_monitoring.index*,.monitoring-es-*,metricbeat-*`
  query:
    bool:
      filter:
        - bool:
            filter:
              # This filters only the documents that have the required fields (ie post 1.16 for the integration)
              - exists:
                  field: "elasticsearch.index.creation_date"
            should:
              - term:
                  event.dataset: "elasticsearch.index"
              - term:
                  event.dataset: "elasticsearch.stack_monitoring.index"
        # Exclude system indices
        - bool:
            should:
              - bool:
                  must_not:
                    - prefix:
                        elasticsearch.index.name: "."
              - bool:
                  filter:
                    - prefix:
                        elasticsearch.index.name: ".ds-"
                  must_not:
                    - prefix:
                        elasticsearch.index.name: ".ds-."
                    - prefix:
                        elasticsearch.index.name: ".ds-ilm-history"
dest:
  index: cluster_tier_and_datastream_contribution_lookup
  pipeline: metrics-chargeback.usage-0.1.4
frequency: 60m
sync:
  time:
    field: "@timestamp"
    delay: 1h
pivot:
  group_by:
    "@timestamp":
      date_histogram:
        field: "@timestamp"
        calendar_interval: 1d
    cluster_name:
      terms:
        field: elasticsearch.cluster.name
    tier:
      terms:
        script:
          lang: painless
          source: >
            if (doc.containsKey('elasticsearch.index.tier') && !doc['elasticsearch.index.tier'].empty) {
              return doc['elasticsearch.index.tier'].value;
            }
            def pref = doc.containsKey('elasticsearch.index.tier_preference') && !doc['elasticsearch.index.tier_preference'].empty ? doc['elasticsearch.index.tier_preference'].value : null;
            if (pref == null) return 'unknown';
            if (pref.contains('data_hot') || pref.contains('data_content')) return 'hot/content';
            if (pref.contains('data_warm')) return 'warm';
            if (pref.contains('data_cold')) return 'cold';
            if (pref.contains('data_frozen')) return 'frozen';
            return 'unknown';
    datastream:
      terms:
        script:
          lang: painless
          source: >
            if (doc.containsKey('elasticsearch.index.datastream') && !doc['elasticsearch.index.datastream'].empty) {
              return doc['elasticsearch.index.datastream'].value;
            }

            def name = doc.containsKey('elasticsearch.index.name') && !doc['elasticsearch.index.name'].empty
              ? doc['elasticsearch.index.name'].value
              : null;
            if (name == null) return 'unknown';

            def matcher = /^(?:partial-)?(?:restored-)?(?:shrink-.{4}-)?(?:\.ds-)?([a-z_0-9\-.]+?)(?:-\d{4}\.\d{2}(?:\.\d{2})?)?(?:-\d+)?$/.matcher(name);
            if (matcher.matches()) {
              return matcher.group(1);
            }
            return 'unknown';
  aggregations:
    tier_and_datastream_sum_indexing_time:
      sum:
        field: elasticsearch.index.total.indexing.index_time_in_millis
    tier_and_datastream_sum_query_time:
      sum:
        field: elasticsearch.index.total.search.query_time_in_millis
    tier_and_datastream_sum_store_size:
      sum:
        field: elasticsearch.index.total.store.size_in_bytes
    tier_and_datastream_sum_data_set_store_size:
      sum:
        field: elasticsearch.index.primaries.store.total_data_set_size_in_bytes
settings:
  # This is required to prevent the transform from clobbering the Fleet-managed mappings.
  deduce_mappings: false
  unattended: true
_meta:
  managed: true
  run_as_kibana_system: false
  # Bump this version to delete, reinstall, and restart the transform during package.
  # Version bump is needed if there is any code change in transform.
  fleet_transform_version: 0.1.4