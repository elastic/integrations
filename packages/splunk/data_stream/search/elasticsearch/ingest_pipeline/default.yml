---
description: Pipeline for processing Alert logs.
processors:
  - drop:
      description: Ignore retry placeholder document.
      if: ctx.retry == true
  - set:
      field: ecs.version
      tag: set_ecs_version
      value: 8.17.0
  - terminate:
      tag: data_collection_error
      if: ctx.error?.message != null && ctx.message == null && ctx.event?.original == null
      description: error message set and no data to process.
  - remove:
      field:
        - organization
        - division
        - team
      ignore_missing: true
      if: ctx.organization instanceof String && ctx.division instanceof String && ctx.team instanceof String
      tag: remove_agentless_tags
      description: >-
        Removes the fields added by Agentless as metadata,
        as they can collide with ECS fields.
  - rename:
      field: message
      tag: rename_message_to_event_original
      target_field: event.original
      ignore_missing: true
      description: Renames the original `message` field to `event.original` to store a copy of the original message. The `event.original` field is not touched if the document already has one; it may happen when Logstash sends the document.
      if: ctx.event?.original == null
  - remove:
      field: message
      tag: remove_message
      ignore_missing: true
      description: The `message` field is no longer required if the document has an `event.original` field.
      if: ctx.event?.original != null
  - fingerprint:
      fields:
        - event.original
      target_field: _id
      ignore_missing: true
  - json:
      field: event.original
      tag: json_event_original
      target_field: splunk.search
      if: ctx.event?.original != null
      on_failure:
        - append:
            field: error.message
            value: 'Processor {{{_ingest.on_failure_processor_type}}} with tag {{{_ingest.on_failure_processor_tag}}} in pipeline {{{_ingest.on_failure_pipeline}}} failed with message: {{{_ingest.on_failure_message}}}'
  - dot_expander:
      field: "*"
      path: splunk.search.ecs_result
      if: ctx.splunk?.search?.ecs_result instanceof Map && ctx.splunk.search.ecs_result.size() != 0
      ignore_failure: true
  - script:
      tag: distribute_expanded_fields
      if: ctx.splunk?.search?.ecs_result instanceof Map && ctx.splunk.search.ecs_result.size() != 0
      source: |-
        def merge(Map dst, Map src) {
          for (def k: src.keySet()) {
            if (src.get(k) instanceof Map && dst.get(k) instanceof Map) {
              dst.put(k, merge(dst.get(k), src.get(k)));
            } else if (src.get(k) instanceof List && dst.get(k) instanceof List) {
              def c = dst.get(k);
              for (def e: src.get(k)) {
                if (!c.contains(e)) {
                  c.add(e);
                }
              }
            } else {
                dst.put(k, src.get(k));
            }
          }
          return dst;
        }
        merge(ctx, ctx.splunk.search.ecs_result);
        ctx.splunk.search.remove("ecs_result");
      on_failure:
        - append:
            field: error.message
            value: 'Processor {{{_ingest.on_failure_processor_type}}} with tag {{{_ingest.on_failure_processor_tag}}} in pipeline {{{_ingest.on_failure_pipeline}}} failed with message: {{{_ingest.on_failure_message}}}'
  - date:
      field: splunk.search._time
      tag: date_raw_timestamp
      target_field: splunk.search._time
      formats:
        - ISO8601
        - epoch_second
        - MM/dd/yy HH:mm:ss
        - HH:mm:ss
      if: ctx.splunk?.search?._time instanceof String && ctx.splunk.search._time != ''
      on_failure:
        - append:
            field: error.message
            value: 'Processor {{{_ingest.on_failure_processor_type}}} with tag {{{_ingest.on_failure_processor_tag}}} in pipeline {{{_ingest.on_failure_pipeline}}} failed with message: {{{_ingest.on_failure_message}}}'
        - remove:
            field: splunk.search._time
  - set:
      field: '@timestamp'
      copy_from: splunk.search.result._time
      ignore_empty_value: true
  - dissect:
      field: splunk.search.result._raw
      pattern: "%{}, %{message}"
      ignore_failure: true
  - set:
      field: message
      copy_from: splunk.search.result._raw
      ignore_empty_value: true
      if: ctx.message == null

  - append:
      field: related.user
      value: '{{{splunk.search.author}}}'
      if: ctx.splunk?.search?.author != null && ctx.splunk.search.author != ''
      allow_duplicates: false
  - append:
      field: related.hosts
      value: '{{{host.name}}}'
      if: ctx.host?.name != null && ctx.host.name != ''
      allow_duplicates: false
  - append:
      field: related.hosts
      value: '{{{splunk.search.result.splunk_server}}}'
      if: ctx.splunk?.search?.result?.splunk_server != null && ctx.splunk.search.result.splunk_server != ''
      allow_duplicates: false
  - remove:
      field:
        - splunk.alert
      tag: remove_custom_duplicate_fields
      ignore_missing: true
      if: ctx.tags == null || !(ctx.tags.contains('preserve_duplicate_custom_fields'))
  - remove:
      field: tmp
      tag: remove_temp
      ignore_missing: true
  - script:
      tag: remove-nulls
      lang: painless
      description: This script processor iterates over the whole document to remove fields with null values.
      source: |
        void handleMap(Map map) {
          map.values().removeIf(v -> {
            if (v instanceof Map) {
                handleMap(v);
            } else if (v instanceof List) {
                handleList(v);
            }
            return v == null || v == '' || (v instanceof Map && v.size() == 0) || (v instanceof List && v.size() == 0)
          });
        }
        void handleList(List list) {
          list.removeIf(v -> {
            if (v instanceof Map) {
                handleMap(v);
            } else if (v instanceof List) {
                handleList(v);
            }
            return v == null || v == '' || (v instanceof Map && v.size() == 0) || (v instanceof List && v.size() == 0)
          });
        }
        handleMap(ctx);
  - set:
      field: event.kind
      tag: set_pipeline_error_to_event_kind
      value: pipeline_error
      if: ctx.error?.message != null
  - append:
      field: tags
      value: preserve_original_event
      allow_duplicates: false
      if: ctx.error?.message != null
on_failure:
  - append:
      field: error.message
      value: >-
        Processor '{{{ _ingest.on_failure_processor_type }}}'
        {{{#_ingest.on_failure_processor_tag}}}with tag '{{{ _ingest.on_failure_processor_tag }}}'
        {{{/_ingest.on_failure_processor_tag}}}failed with message '{{{ _ingest.on_failure_message }}}'
  - set:
      field: event.kind
      tag: set_pipeline_error_to_event_kind
      value: pipeline_error
  - append:
      field: tags
      value: preserve_original_event
      allow_duplicates: false
