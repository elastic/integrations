config_version: 2
interval: {{interval}}
{{#if enable_request_tracer}}
resource.tracer.filename: "../../logs/cel/http-request-trace-*.ndjson"
resource.tracer.maxbackups: 5
{{/if}}
resource.url: {{api_url}}
fields_under_root: true
keep_null: true
state:
  client_id: {{client_id}}
  client_secret: {{client_secret}}
  page_size: {{batch_size}}
  look_back: {{initial_interval}}
  path: /api/archive/get-archive-search-logs
  data_path: logs
  start_field: start
  end_field: end
  time_field: createTime
redact:
  fields:
    - client_id
    - client_secret
    - token.access_token
program: |
  // This program is shared amongst archive_search_logs, dlp_logs,
  // message_release_logs, ttp_ap_logs, ttp_ip_logs, and ttp_url_logs.
  // If it is changed here changes should be reflected in the other
  // data streams. Do not differentiate the logic between these data
  // streams lightly; use the state variable for this unless absolutely
  // required.
  state.with(
    (
      (has(state.?token.expires) && now() < timestamp(state.token.expires)) ?
        // The token we have is still valid.
        state.token
      :
        // Get a new token.
        post_request(state.url.trim_right("/") + "/oauth/token", "application/x-www-form-urlencoded",
          {
            "client_id": [state.client_id],
            "client_secret": [state.client_secret],
            "grant_type": ["client_credentials"],
          }.format_query()
        ).do_request().as(auth, auth.StatusCode == 200 ?
          bytes(auth.Body).decode_json().as(auth_body, auth_body.with({
            // Include 60s grace period to avoid attempting to make
            // a request with a stale authentication token.
            "expires": now()+duration(string(int(auth_body.expires_in)-60)+"s"),
          }))
        :
          {
            "events": {
              "error": {
                "code": string(auth.StatusCode),
                "id": string(auth.Status),
                "message": "POST /oauth/token: "+(
                  size(auth.Body) != 0 ?
                    string(auth.Body)
                  :
                    string(auth.Status) + ' (' + string(auth.StatusCode) + ')'
                ),
              },
            },
            "want_more": false,
          }
        )
    ).as(token, !has(token.access_token) ? token :
      {
        "data": state.?last_page.data.orValue([{
          state.start_field: state.?cursor.last.orValue((now - duration(state.look_back)).format(time_layout.RFC3339)),
          state.end_field: now.format(time_layout.RFC3339),
        }]),
      }.as(req,
        post_request(state.url.trim_right("/") + state.path, "application/json",
          {
            "meta": {
              "pagination": {
                "pageSize": state.page_size,
                ?"pageToken": state.?last_page.next,
              }
            },
            "data": req.data,
          }.encode_json()
        ).with({
          "Header": {
            "Authorization": ["Bearer " + token.access_token],
            "Accept": ["application/json"],
            "Content-Type": ["application/json"],
          }
        }).do_request().as(resp, resp.StatusCode == 200 ?
          bytes(resp.Body).decode_json().as(body, body.?fail.orValue([]).size() == 0 ?
            {
              "events": body.data.map(e, e[state.data_path].map(l, {"message": l.encode_json()})).flatten(),
              "cursor": {
                "last": ([now] + body.data.map(e,
                  e[state.data_path].map(l,
                    l[state.time_field].parse_time(["2006-01-02T15:04:05-0700", time_layout.RFC3339])
                  )
                ).flatten()).max().format(time_layout.RFC3339),
              },
              ?"last_page": has(body.?meta.pagination.next) && size(body.data) != 0 ?
                optional.of({
                  ?"next": body.?meta.pagination.next,
                  "data": req.data,
                })
              :
                optional.none(),
              "token": {
                "access_token": token.access_token,
                "expires": token.expires,
              },
              "want_more": has(body.?meta.pagination.next) && size(body.data) != 0,
            }
          :
            // Mimecast can return failure states with a 200. This
            // is detected by a non-empty fail array at the root
            // of the response body. Don't attempt to parse this
            // out, just dump the whole body into the error message.
            {
              "events": {
                "error": {
                  "code": string(resp.StatusCode),
                  "id": string(resp.Status),
                  "message": "POST " + state.path + ":" + string(resp.Body), // We know this is not empty.
                },
              },
              "want_more": false,
            }
          )
        :
          {
            "events": {
              "error": {
                "code": string(resp.StatusCode),
                "id": string(resp.Status),
                "message": "POST " + state.path + ": " + (
                  size(resp.Body) != 0 ?
                    string(resp.Body)
                  :
                    string(resp.Status) + ' (' + string(resp.StatusCode) + ')'
                ),
              },
            },
            "want_more": false,
          }
        )
      )
    )
  )
tags:
{{#if preserve_original_event}}
  - preserve_original_event
{{/if}}
{{#each tags as |tag|}}
  - {{tag}}
{{/each}}
{{#contains "forwarded" tags}}
publisher_pipeline.disable_host: true
{{/contains}}
{{#if processors}}
processors:
{{processors}}
{{/if}}
