config_version: "2"
interval: {{period}}
resource.url: "{{url}}/_node"
{{#if resource_ssl}}
resource.ssl:
  {{resource_ssl}}
{{/if}}

{{#if username}}
auth.basic.user: {{escape_string username}}
{{/if}}
{{#if password}}
auth.basic.password: {{escape_string password}}
{{/if}}
{{#if condition}}
condition: {{ condition }}
{{/if}}

redact:
  fields: ~


program: |
  get(state.url + "/stats?graph=true&vertices=true").as(resp, bytes(resp.Body).decode_json().as(body,
    body.pipelines.map(pipeline_name, pipeline_name != ".monitoring-logstash", {
      "name": pipeline_name,
      "info": get(state.url + "/pipelines/" + pipeline_name).as(resp,
        bytes(resp.Body).decode_json().as(pipes,
          has(pipes.pipeline) && has (pipes.pipelines) ?
            pipes.pipelines[pipeline_name]
          :
            []
        )
      ),
      "elasticsearch.cluster.id": has(body.pipelines[pipeline_name].vertices) ?
        body.pipelines[pipeline_name].vertices.map(vertex, has(vertex.cluster_uuid), vertex.cluster_uuid)
      :
        [],
      "host":{
        "name":body.name,
        "address":body.http_address,
      },
      "total":{
        "flow":body.pipelines[pipeline_name].flow,
        "time":{
          "queue_push_duration": {
            "ms": has(body.pipelines[pipeline_name].events.queue_push_duration_in_millis) ?
              body.pipelines[pipeline_name].events.queue_push_duration_in_millis
            :
              [],
          },
          "duration":{
            "ms": has(body.pipelines[pipeline_name].events.duration_in_millis) ?
              body.pipelines[pipeline_name].events.duration_in_millis
            :
              [],
          },
        },
        "reloads":{
          "successes":body.pipelines[pipeline_name].reloads.successes,
          "failures":body.pipelines[pipeline_name].reloads.failures
        },
        "events":{
          "out": has(body.pipelines[pipeline_name].events.out) ?
            body.pipelines[pipeline_name].events.out
          :
            [],
          "in": has(body.pipelines[pipeline_name].events.out) ? // This deliberately uses 'out' as `has` does not accept `in`
            body.pipelines[pipeline_name].events['in']
          :
            [],
          "filtered": has(body.pipelines[pipeline_name].events.filtered) ?
            body.pipelines[pipeline_name].events.filtered
          :
            [],
        },
        "queues":{
          "type": has(body.pipelines[pipeline_name].queue.type) ?
            body.pipelines[pipeline_name].queue.type
          :
            [],
          "events": has(body.pipelines[pipeline_name].queue.events_count) ?
            body.pipelines[pipeline_name].queue.events_count
          :
            [],
          "current_size":{
            "bytes": has(body.pipelines[pipeline_name].queue.queue_size_in_bytes) ?
              body.pipelines[pipeline_name].queue.queue_size_in_bytes
            :
              [],
          },
          "max_size":{
            "bytes": has(body.pipelines[pipeline_name].queue.max_queue_size_in_bytes) ?
              body.pipelines[pipeline_name].queue.max_queue_size_in_bytes
            :
              [],
          }
        }
      }
    }))).as(pipelines, {
      "events": pipelines.map(pipeline, {
        "logstash": {"pipeline":pipeline}
      })
    })
