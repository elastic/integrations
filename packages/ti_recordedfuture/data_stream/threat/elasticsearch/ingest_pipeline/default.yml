---
description: Pipeline for parsing Recorded Future threat intel.
processors:
#
# Set basic ECS fields.
#
  - set:
      field: ecs.version
      value: '8.11.0'
  - set:
      field: event.dataset
      value: "ti_recordedfuture.threat"
  - set:
      field: event.kind
      value: enrichment
  - set:
      field: event.category
      value: [threat]
  - set:
      field: event.type
      value: [indicator]
  - set:
      field: threat.feed.name
      value: "Recorded Future"
#
# TODO: Add dashboard
#
#  - set:
#      field: threat.feed.dashboard_id
#      value: "recordedfuture-96fe1e60-4261-11ec-b7be-d3026acdf1cf"

  - rename:
      field: message
      target_field: event.original
      ignore_missing: true
      if: ctx.event?.original == null

#
# Decode event.original as JSON if it starts with the "{" character.
# This is the common case when events are ingested from the API, as httpjson
# transforms the CSV to a JSON message.
#
  - json:
      field: event.original
      target_field: json
      if: 'ctx.event?.original != null && ctx.event.original.startsWith("{")'
      on_failure:
        - fail:
            message: "Failed decoding message field as JSON: {{{ _ingest.on_failure_message }}}"

#
# Decode event.original as CSV when the above processor didn't execute.
# This is used when ingesting CSV lines from a file.
#
  - pipeline:
      name: '{{ IngestPipeline "decode_csv" }}'
      if: 'ctx.json == null'
      on_failure:
        - fail:
            message: "Failed decoding message field as CSV: {{{ _ingest.on_failure_message }}}"

#
# Decode EvidenceDetails column as JSON.
#
  - json:
      field: json.EvidenceDetails
      target_field: _temp_.EvidenceDetails
      ignore_failure: true

  - rename:
      field: _temp_.EvidenceDetails.EvidenceDetails
      target_field: json.evidence_details
      ignore_missing: true

  - foreach:
      field: json.evidence_details
      ignore_missing: true
      processor:
        append:
          field: _temp_.providers
          value: "{{{ _ingest._value.EvidenceString }}}"
  - foreach:
      field: _temp_.providers
      ignore_missing: true
      processor:
        gsub:
          field: '_ingest._value'
          pattern: '^(?:.+sources?(?: including)?: (.*?)(?:\. |$))|(.*)$'
          replacement: '$1'
  - foreach:
      field: _temp_.providers
      ignore_missing: true
      processor:
        split:
          field: '_ingest._value'
          separator: ', *'
  - script:
      description: Iterate through the nested arrays and remove the empty strings
      lang: painless
      ignore_failure: true
      source: |
        if (ctx._temp_ != null && ctx._temp_.providers != null) {
          ctx._temp_.providers = ctx._temp_.providers.stream()
            .filter(p -> p != null && p.size() > 0 && !p.get(0).isEmpty())
            .collect(Collectors.toList());
        }
  - foreach:
      field: _temp_.providers
      ignore_missing: true
      processor:
        foreach:
          field: '_ingest._value'
          ignore_missing: true
          processor:
            append:
              field: threat.indicator.provider
              value: '{{{ _ingest._value }}}'
              allow_duplicates: false

  # Convert evidence_details fields to snakecase
  - script:
      description: Convert evidence_details fields to snakecase.
      if: ctx.json.evidence_details instanceof List && ctx.json.evidence_details.size() > 0
      tag: script-evidence_details_snakecase
      lang: painless
      source: |
        Map keysToSnakeCase(Map m) {
          def regex = /_?([a-z])([A-Z]+)/;
          def out = [:];

          for (entry in m.entrySet()) {
            def k = entry.getKey();
            def v = entry.getValue();

            if (v instanceof Map) {
              v = keysToSnakeCase(v);
            } else if (v instanceof List) {
              for (int i = 0; i < v.size(); i++) {
                def item = v.get(i);
                if (item instanceof Map) {
                  v.set(i, keysToSnakeCase(item));
                }
              }
            }

            k = regex.matcher(k).replaceAll('$1_$2').toLowerCase();
            out.put(k, v);
          }

          return out;
        }
        List evidence_details = new ArrayList();
        for (evidence in ctx.json.evidence_details){
          evidence_details.add(keysToSnakeCase(evidence));
        }
        ctx.json.evidence_details = evidence_details;
      on_failure:
        - append:
            field: error.message
            value: 'Processor {{{_ingest.on_failure_processor_type}}} with tag {{{_ingest.on_failure_processor_tag}}} in pipeline {{{_ingest.on_failure_pipeline}}} failed with message: {{{_ingest.on_failure_message}}}'

  # Convert evidence_details timestamps to date
  - foreach:
      field: json.evidence_details
      ignore_missing: true
      processor:
        date:
          field: '_ingest._value.timestamp'
          tag: date_time
          target_field: '_ingest._value.timestamp'
          formats:
            - ISO8601
          on_failure:
            - remove:
                field: '_ingest._value.timestamp'
                ignore_missing: true
            - append:
                field: error.message
                value: 'Processor {{{_ingest.on_failure_processor_type}}} with tag {{{_ingest.on_failure_processor_tag}}} in pipeline {{{_ingest.on_failure_pipeline}}} failed with message: {{{_ingest.on_failure_message}}}'

#
# Hash indicators (threat.indicator.type=file)
# As risklist indicators don't have a "type" field, it's necessary
# to detect the kind of indicator in the Name field.
#
# An indicator is of type `hash` when the Algorithm field is present.
#
  - set:
      field: threat.indicator.type
      value: file
      if: 'ctx.json.Algorithm != null'
  - script:
      lang: painless
      description: >
        Map file hashes.
      if: "ctx.json.Algorithm != null"
      params:
        MD5: md5
        SHA-1: sha1
        SHA-256: sha256
        SHA-384: sha384
        SHA-512: sha512
      source: >-
        def key = params[ctx.json.Algorithm];
        if (key == null) {
          throw new Exception("Unsupported hash algorithm '" + ctx.json.Algorithm + "'");
        }
        def hashes = [key:ctx.json.Name];
        ctx["_hashes"] = hashes;
      on_failure:
        - append:
            field: error.message
            value: "Failed to map fileHashes field: {{{ _ingest.on_failure_message }}}"
  - rename:
      field: _hashes
      target_field: threat.indicator.file.hash
      ignore_missing: true

#
# IP indicators (threat.indicator.type=ipvN-addr)
#
# An indicator is of type `ip` if Name is a valid IP address.
#
  - convert:
      field: json.Name
      target_field: threat.indicator.ip
      type: ip
      ignore_failure: true
      if: 'ctx.threat?.indicator?.type == null'
  - set:
      field: threat.indicator.type
      value: ipv4-addr
      if: 'ctx.threat?.indicator?.ip != null && !ctx.threat.indicator.ip.contains(":")'
  - set:
      field: threat.indicator.type
      value: ipv6-addr
      if: 'ctx.threat?.indicator?.ip != null && ctx.threat.indicator.ip.contains(":")'

#
# URL indicators (threat.indicator.type=url)
# An indicator is of type `url` if Name contains a slash character.
#
  - set:
      field: threat.indicator.type
      value: url
      if: 'ctx.threat?.indicator?.type == null && ctx.json.Name.contains("/")'
  - uri_parts:
      field: json.Name
      target_field: threat.indicator.url
      keep_original: true
      if: 'ctx.threat?.indicator?.type == "url"'
      on_failure:
        - set:
            field: threat.indicator.url.original
            copy_from: json.Name
  - set:
      field: threat.indicator.url.full
      copy_from: json.Name
      if: 'ctx.threat?.indicator?.type == "url"'

#
# Domain indicators (threat.indicator.type=domain)
# This is a catch-all type.
#
  - set:
      field: threat.indicator.type
      value: domain-name
      if: 'ctx.threat?.indicator?.type == null'
  - set:
      field: threat.indicator.url.domain
      value: '{{{ json.Name }}}'
      ignore_empty_value: true
      if: 'ctx.threat?.indicator?.type == "domain-name" && ctx.threat?.indicator?.url?.domain == null'

  # Add Threat scanner_stats and sightings fields
  - script:
      description: Calculate threat.indicator.scanner_stats as sum of sources_count
      lang: painless
      tag: script-scanner_stats
      if: ctx.json.evidence_details instanceof List && ctx.json.evidence_details.size() > 0
      source: |
        def sum_sources_count = 0;
        for (evidence in ctx.json.evidence_details){
          if (evidence['sources_count'] != null){
            sum_sources_count += evidence['sources_count'];
          }
        }
        ctx.threat.indicator.scanner_stats = sum_sources_count;
      on_failure:
        - append:
            field: error.message
            value: 'Processor {{{_ingest.on_failure_processor_type}}} with tag {{{_ingest.on_failure_processor_tag}}} in pipeline {{{_ingest.on_failure_pipeline}}} failed with message: {{{_ingest.on_failure_message}}}'
  - script:
      description: Calculate threat.indicator.sightings as sum of sightings_count
      lang: painless
      tag: script-sightings
      if: ctx.json.evidence_details instanceof List && ctx.json.evidence_details.size() > 0
      source: |
        def sum_sightings_count = 0;
        for (evidence in ctx.json.evidence_details){
          if (evidence['sightings_count'] != null){
            sum_sightings_count += evidence['sightings_count'];
          }
        }
        ctx.threat.indicator.sightings = sum_sightings_count;
      on_failure:
        - append:
            field: error.message
            value: 'Processor {{{_ingest.on_failure_processor_type}}} with tag {{{_ingest.on_failure_processor_tag}}} in pipeline {{{_ingest.on_failure_pipeline}}} failed with message: {{{_ingest.on_failure_message}}}'


#
# Normalize Risk
#
  - convert:
      field: json.Risk
      target_field: event.risk_score
      ignore_missing: true
      type: float
      on_failure:
        - append:
            field: error.message
            value: "Risk score `{{{ json.Risk }}}` cannot be converted to float: {{{ _ingest.on_failure_message }}}"

#
# Save fields without an ECS mapping under `recordedfuture`.
#
  - rename:
      field: json.RiskString
      target_field: json.risk_string
      ignore_missing: true
  - rename:
      field: json.Name
      target_field: json.name
  - rename:
      field: json
      target_field: recordedfuture
  - rename:
      target_field: recordedfuture.list
      field: _conf.list
      if: ctx._conf?.list != null

#
# Cleanup
#
  - remove:
      field: event.original
      if: "ctx?.tags == null || !(ctx.tags.contains('preserve_original_event'))"
      ignore_failure: true
      ignore_missing: true
  - remove:
      field:
        - recordedfuture.Algorithm
        - recordedfuture.EvidenceDetails
        - recordedfuture.Name
        - recordedfuture.Risk
        - _temp_
        - _conf
      ignore_missing: true
on_failure:
  - set:
      field: event.kind
      value: pipeline_error
  - append:
      field: error.message
      value: '{{{ _ingest.on_failure_message }}}'
