# Amazon Kinesis Data Stream

The Amazon Kinesis integration allows you to monitor [Amazon Kinesis Data Stream](https://aws.amazon.com/kinesis/data-streams/)â€”
a serverless streaming data service that makes it easy to capture, process, and store data streams at any scale.

Use the Amazon Kinesis integration to monitor Amazon Kinesis Data Streams. Then visualize that data in Kibana, create 
alerts to notify you if something goes wrong, and reference metrics when troubleshooting an issue.

**IMPORTANT: Extra AWS charges on AWS API requests will be generated by this integration. Please refer to the AWS integration for more details.**

## Data streams

The Amazon Kinesis integration collects one type of data: metrics.

**Metrics** give you insight into the state of Amazon Kinesis.
Metrics collected by this integration include information about operations related to Amazon Kinesis records, shards, and more. See more details in the [Metrics reference](#metrics-reference).

## Requirements

You need Elasticsearch for storing and searching your data and Kibana for visualizing and managing it.
You can use our hosted Elasticsearch Service on Elastic Cloud, which is recommended, or self-manage the Elastic Stack on your own hardware.

Before using any AWS integration you will need:

* **AWS Credentials** to connect with your AWS account.
* **AWS Permissions** to make sure the user you're using to connect has permission to share the relevant data.

For more details about these requirements, please take a look at the [AWS integration documentation](https://docs.elastic.co/integrations/aws#requirements).

## Setup

Use this integration if you only need to collect data from the Amazon Kinesis service.

If you want to collect data from two or more AWS services, consider using the **AWS** integration.
When you configure the AWS integration, you can collect data from as many AWS services as you'd like.

For step-by-step instructions on how to set up an integration, see the
[Getting started](https://www.elastic.co/guide/en/welcome-to-elastic/current/getting-started-observability.html) guide.

## Metrics

An example event for `kinesis` looks as following:

```json
{
    "@timestamp": "2022-07-27T20:56:00.000Z",
    "agent": {
        "ephemeral_id": "51866723-6dfa-4a72-a68e-f439d5de7f53",
        "id": "2d4b09d0-cdb6-445e-ac3f-6415f87b9864",
        "name": "docker-fleet-agent",
        "type": "metricbeat",
        "version": "8.3.2"
    },
    "aws": {
        "cloudwatch": {
            "namespace": "AWS/Kinesis"
        },
        "dimensions": {
            "StreamName": "fb-test"
        },
        "kinesis": {
            "metrics": {
                "GetRecords_Bytes": {
                    "avg": 0
                },
                "GetRecords_IteratorAgeMilliseconds": {
                    "avg": 0
                },
                "GetRecords_Latency": {
                    "avg": 9.46
                },
                "GetRecords_Records": {
                    "sum": 0
                },
                "GetRecords_Success": {
                    "sum": 150
                },
                "ReadProvisionedThroughputExceeded": {
                    "avg": 0
                }
            }
        }
    },
    "cloud": {
        "account": {
            "id": "428152502467",
            "name": "elastic-beats"
        },
        "provider": "aws",
        "region": "us-east-1"
    },
    "data_stream": {
        "dataset": "aws.kinesis",
        "namespace": "default",
        "type": "metrics"
    },
    "ecs": {
        "version": "8.11.0"
    },
    "elastic_agent": {
        "id": "2d4b09d0-cdb6-445e-ac3f-6415f87b9864",
        "snapshot": false,
        "version": "8.3.2"
    },
    "event": {
        "agent_id_status": "verified",
        "dataset": "aws.kinesis",
        "duration": 10483932100,
        "ingested": "2022-07-27T20:56:00.000Z",
        "module": "aws"
    },
    "metricset": {
        "name": "cloudwatch",
        "period": 300000
    },
    "service": {
        "type": "aws"
    }
}
```

**ECS Field Reference**

Please refer to the following [document](https://www.elastic.co/guide/en/ecs/current/ecs-field-reference.html) for detailed information on ECS fields.

**Exported fields**

| Field | Description | Type | Metric Type |
|---|---|---|---|
| @timestamp | Event timestamp. | date |  |
| agent.id | Unique identifier of this agent (if one exists). Example: For Beats this would be beat.id. | keyword |  |
| aws.cloudwatch.namespace | The namespace specified when query cloudwatch api. | keyword |  |
| aws.dimensions.StreamName | The name of the Kinesis stream. All available statistics are filtered by StreamName. | keyword |  |
| aws.kinesis.metrics.GetRecords_Bytes.avg | The average number of bytes retrieved from the Kinesis stream, measured over the specified time period. | double | gauge |
| aws.kinesis.metrics.GetRecords_IteratorAgeMilliseconds.avg | The age of the last record in all GetRecords calls made against a Kinesis stream, measured over the specified time period. Age is the difference between the current time and when the last record of the GetRecords call was written to the stream. | double | gauge |
| aws.kinesis.metrics.GetRecords_Latency.avg | The time taken per GetRecords operation, measured over the specified time period. | double | gauge |
| aws.kinesis.metrics.GetRecords_Records.sum | The number of records retrieved from the shard, measured over the specified time period. | long | gauge |
| aws.kinesis.metrics.GetRecords_Success.sum | The number of successful GetRecords operations per stream, measured over the specified time period. | long | gauge |
| aws.kinesis.metrics.IncomingBytes.avg | The number of bytes successfully put to the Kinesis stream over the specified time period. This metric includes bytes from PutRecord and PutRecords operations. | double | gauge |
| aws.kinesis.metrics.IncomingRecords.avg | The number of records successfully put to the Kinesis stream over the specified time period. This metric includes record counts from PutRecord and PutRecords operations. | double | gauge |
| aws.kinesis.metrics.PutRecord_Bytes.avg | The number of bytes put to the Kinesis stream using the PutRecord operation over the specified time period. | double | gauge |
| aws.kinesis.metrics.PutRecord_Latency.avg | The time taken per PutRecord operation, measured over the specified time period. | double | gauge |
| aws.kinesis.metrics.PutRecord_Success.avg | The percentage of successful writes to a Kinesis stream, measured over the specified time period. | double | gauge |
| aws.kinesis.metrics.PutRecords_Bytes.avg | The average number of bytes put to the Kinesis stream using the PutRecords operation over the specified time period. | double | gauge |
| aws.kinesis.metrics.PutRecords_FailedRecords.sum | The number of records rejected due to internal failures in a PutRecords operation per Kinesis data stream, measured over the specified time period. | long | gauge |
| aws.kinesis.metrics.PutRecords_Latency.avg | The average time taken per PutRecords operation, measured over the specified time period. | double | gauge |
| aws.kinesis.metrics.PutRecords_Success.avg | The total number of PutRecords operations where at least one record succeeded, per Kinesis stream, measured over the specified time period. | long | gauge |
| aws.kinesis.metrics.PutRecords_SuccessfulRecords.sum | The number of successful records in a PutRecords operation per Kinesis data stream, measured over the specified time period. | long | gauge |
| aws.kinesis.metrics.PutRecords_ThrottledRecords.sum | The number of records rejected due to throttling in a PutRecords operation per Kinesis data stream, measured over the specified time period. | long | gauge |
| aws.kinesis.metrics.PutRecords_TotalRecords.sum | The total number of records sent in a PutRecords operation per Kinesis data stream, measured over the specified time period. | long | gauge |
| aws.kinesis.metrics.ReadProvisionedThroughputExceeded.avg | The number of GetRecords calls throttled for the stream over the specified time period. | long | gauge |
| aws.kinesis.metrics.SubscribeToShardEvent_Bytes.avg | The number of bytes received from the shard, measured over the specified time period. | long | gauge |
| aws.kinesis.metrics.SubscribeToShardEvent_MillisBehindLatest.avg | The difference between the current time and when the last record of the SubscribeToShard event was written to the stream. | long | gauge |
| aws.kinesis.metrics.SubscribeToShardEvent_Records.sum | The number of records received from the shard, measured over the specified time period. | long | gauge |
| aws.kinesis.metrics.SubscribeToShardEvent_Success.avg | This metric is emitted every time an event is published successfully. It is only emitted when there's an active subscription. | long | gauge |
| aws.kinesis.metrics.SubscribeToShard_RateExceeded.avg | This metric is emitted when a new subscription attempt fails because there already is an active subscription by the same consumer or if you exceed the number of calls per second allowed for this operation. | long | gauge |
| aws.kinesis.metrics.SubscribeToShard_Success.avg | This metric records whether the SubscribeToShard subscription was successfully established. | long | gauge |
| aws.kinesis.metrics.WriteProvisionedThroughputExceeded.avg | The number of records rejected due to throttling for the stream over the specified time period. This metric includes throttling from PutRecord and PutRecords operations. | long | gauge |
| aws.tags | Tag key value pairs from aws resources. | flattened |  |
| cloud | Fields related to the cloud or infrastructure the events are coming from. | group |  |
| cloud.account.id | The cloud account or organization id used to identify different entities in a multi-tenant environment. Examples: AWS account id, Google Cloud ORG Id, or other unique identifier. | keyword |  |
| cloud.image.id | Image ID for the cloud instance. | keyword |  |
| cloud.region | Region in which this host, resource, or service is located. | keyword |  |
| data_stream.dataset | Data stream dataset. | constant_keyword |  |
| data_stream.namespace | Data stream namespace. | constant_keyword |  |
| data_stream.type | Data stream type. | constant_keyword |  |
| error | These fields can represent errors of any kind. Use them for errors that happen while fetching events or in cases where the event itself contains an error. | group |  |
| event.module | Event module | constant_keyword |  |
| host.containerized | If the host is a container. | boolean |  |
| host.os.build | OS build information. | keyword |  |
| host.os.codename | OS codename, if any. | keyword |  |
