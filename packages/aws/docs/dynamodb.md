# Amazon DynamoDB

The Amazon DynamoDB integration allows you to monitor [Amazon DynamoDB](https://aws.amazon.com/dynamodb/)â€”a key-value NoSQL database.

Use the Amazon DynamoDB integration to collect metrics related to your Amazon DynamoDB databases.
Then visualize that data in Kibana, create alerts to notify you if something goes wrong, and reference metrics when troubleshooting an issue.

For example, you could use this data to visualize consumed read and write capacity units. You can then create alerts based on used or unused capacity, so that the relevant users can better scale their provisioned throughput capacity. This might mean they increase the capacity to provide more resources, or reduce capacity to save on costs.

**IMPORTANT: Extra AWS charges on AWS API requests will be generated by this integration. Please refer to the AWS integration for more details.**

## Data streams

The Amazon DynamoDB integration collects one type of data: metrics.

**Metrics** give you insight into the state of Amazon DynamoDB.
Metrics collected by the Amazon DynamoDB integration include the maximum number of read and write capacity units that can be used by an account, consume capacity units, throttle events, and more. See more details in the [Metrics reference](#metrics-reference).

## Requirements

You need Elasticsearch for storing and searching your data and Kibana for visualizing and managing it.
You can use our hosted Elasticsearch Service on Elastic Cloud, which is recommended, or self-manage the Elastic Stack on your own hardware.

Before using any AWS integration you will need:

* **AWS Credentials** to connect with your AWS account.
* **AWS Permissions** to make sure the user you're using to connect has permission to share the relevant data.

For more details about these requirements, please take a look at the [AWS integration documentation](https://docs.elastic.co/integrations/aws#requirements).

## Setup

Use this integration if you only need to collect data from AWS DynamoDB.

If you want to collect data from two or more AWS services, consider using the **AWS** integration.
When you configure the AWS integration, you can collect data from as many AWS services as you'd like.

For step-by-step instructions on how to set up an integration, see the
[Getting started](https://www.elastic.co/guide/en/welcome-to-elastic/current/getting-started-observability.html) guide.

## Metrics reference

The `dynamodb` data stream collects DynamoDB metrics from AWS.
An example event for `dynamodb` looks like this:

An example event for `dynamodb` looks as following:

```json
{
    "@timestamp": "2022-07-25T21:53:00.000Z",
    "agent": {
        "ephemeral_id": "64a12b83-a4f1-487c-8d2c-9581fda6ca2a",
        "id": "2d4b09d0-cdb6-445e-ac3f-6415f87b9864",
        "name": "docker-fleet-agent",
        "type": "metricbeat",
        "version": "8.3.2"
    },
    "aws": {
        "cloudwatch": {
            "namespace": "AWS/DynamoDB"
        },
        "dynamodb": {
            "metrics": {
                "AccountMaxReads": {
                    "max": 80000
                },
                "AccountMaxTableLevelReads": {
                    "max": 40000
                },
                "AccountMaxTableLevelWrites": {
                    "max": 40000
                },
                "AccountMaxWrites": {
                    "max": 80000
                },
                "AccountProvisionedReadCapacityUtilization": {
                    "avg": 0.01
                },
                "AccountProvisionedWriteCapacityUtilization": {
                    "avg": 0.01
                },
                "MaxProvisionedTableReadCapacityUtilization": {
                    "max": 0.01
                },
                "MaxProvisionedTableWriteCapacityUtilization": {
                    "max": 0.01
                }
            }
        }
    },
    "cloud": {
        "account": {
            "id": "428152502467",
            "name": "elastic-beats"
        },
        "provider": "aws",
        "region": "eu-central-1"
    },
    "data_stream": {
        "dataset": "aws.dynamodb",
        "namespace": "default",
        "type": "metrics"
    },
    "ecs": {
        "version": "8.11.0"
    },
    "elastic_agent": {
        "id": "2d4b09d0-cdb6-445e-ac3f-6415f87b9864",
        "snapshot": false,
        "version": "8.3.2"
    },
    "event": {
        "agent_id_status": "verified",
        "dataset": "aws.dynamodb",
        "duration": 10586366300,
        "ingested": "2022-07-25T21:57:51Z",
        "module": "aws"
    },
    "metricset": {
        "name": "cloudwatch",
        "period": 300000
    },
    "service": {
        "type": "aws"
    }
}
```

**Exported fields**

| Field | Description | Type | Metric Type |
|---|---|---|---|
| @timestamp | Event timestamp. | date |  |
| agent.id | Unique identifier of this agent (if one exists). Example: For Beats this would be beat.id. | keyword |  |
| aws.cloudwatch.namespace | The namespace specified when query cloudwatch api. | keyword |  |
| aws.dimensions.DelegatedOperation | This dimension limits the data to operations DynamoDB performs on your behalf. | keyword |  |
| aws.dimensions.GlobalSecondaryIndexName | This dimension limits the data to a global secondary index on a table. | keyword |  |
| aws.dimensions.Operation | This dimension limits the data to one of the DynamoDB operations, such as PutItem, DeleteItem, UpdateItem, etc. | keyword |  |
| aws.dimensions.OperationType | This dimension limits the data to operation type Read and Write. | keyword |  |
| aws.dimensions.ReceivingRegion | This dimension limits the data to a particular AWS region. | keyword |  |
| aws.dimensions.StreamLabel | This dimension limits the data to a specific stream label. | keyword |  |
| aws.dimensions.TableName | This dimension limits the data to a specific table. | keyword |  |
| aws.dimensions.Verb | This dimension limits the data to one of the DynamoDB PartiQL verbs. | keyword |  |
| aws.dynamodb.metrics.AccountMaxReads.max | The maximum number of read capacity units that can be used by an account. This limit does not apply to on-demand tables or global secondary indexes. | long | gauge |
| aws.dynamodb.metrics.AccountMaxTableLevelReads.max | The maximum number of read capacity units that can be used by a table or global secondary index of an account. For on-demand tables this limit caps the maximum read request units a table or a global secondary index can use. | long | gauge |
| aws.dynamodb.metrics.AccountMaxTableLevelWrites.max | The maximum number of write capacity units that can be used by a table or global secondary index of an account. For on-demand tables this limit caps the maximum write request units a table or a global secondary index can use. | long | gauge |
| aws.dynamodb.metrics.AccountMaxWrites.max | The maximum number of write capacity units that can be used by an account. This limit does not apply to on-demand tables or global secondary indexes. | long | gauge |
| aws.dynamodb.metrics.AccountProvisionedReadCapacityUtilization.avg | The average percentage of provisioned read capacity units utilized by the account. | double | gauge |
| aws.dynamodb.metrics.AccountProvisionedWriteCapacityUtilization.avg | The average percentage of provisioned write capacity units utilized by the account. | double | gauge |
| aws.dynamodb.metrics.ConditionalCheckFailedRequests.sum | The number of failed attempts to perform conditional writes. | long | gauge |
| aws.dynamodb.metrics.ConsumedReadCapacityUnits.avg |  | double | gauge |
| aws.dynamodb.metrics.ConsumedReadCapacityUnits.sum |  | long | gauge |
| aws.dynamodb.metrics.ConsumedWriteCapacityUnits.avg |  | double | gauge |
| aws.dynamodb.metrics.ConsumedWriteCapacityUnits.sum |  | long | gauge |
| aws.dynamodb.metrics.MaxProvisionedTableReadCapacityUtilization.max | The percentage of provisioned read capacity units utilized by the highest provisioned read table or global secondary index of an account. | double | gauge |
| aws.dynamodb.metrics.MaxProvisionedTableWriteCapacityUtilization.max | The percentage of provisioned write capacity utilized by the highest provisioned write table or global secondary index of an account. | double | gauge |
| aws.dynamodb.metrics.OnlineIndexPercentageProgress.avg | The percentage of completion when a new global secondary index is being added to a table. | double | gauge |
| aws.dynamodb.metrics.PendingReplicationCount.sum | The number of item updates that are written to one replica table, but that have not yet been written to another replica in the global table. | long | gauge |
| aws.dynamodb.metrics.ProvisionedReadCapacityUnits.avg | The number of provisioned read capacity units for a table or a global secondary index. | double | gauge |
| aws.dynamodb.metrics.ProvisionedWriteCapacityUnits.avg | The number of provisioned write capacity units for a table or a global secondary index. | double | gauge |
| aws.dynamodb.metrics.ReadThrottleEvents.sum | Requests to DynamoDB that exceed the provisioned read capacity units for a table or a global secondary index. | long | gauge |
| aws.dynamodb.metrics.ReplicationLatency.avg |  | double | gauge |
| aws.dynamodb.metrics.ReplicationLatency.max |  | double | gauge |
| aws.dynamodb.metrics.SuccessfulRequestLatency.avg |  | double | gauge |
| aws.dynamodb.metrics.SuccessfulRequestLatency.max |  | double | gauge |
| aws.dynamodb.metrics.SystemErrors.sum | The requests to DynamoDB or Amazon DynamoDB Streams that generate an HTTP 500 status code during the specified time period. | long | gauge |
| aws.dynamodb.metrics.ThrottledRequests.sum | Requests to DynamoDB that exceed the provisioned throughput limits on a resource (such as a table or an index). | long | gauge |
| aws.dynamodb.metrics.TransactionConflict.avg |  | double | gauge |
| aws.dynamodb.metrics.TransactionConflict.sum |  | long | gauge |
| aws.dynamodb.metrics.WriteThrottleEvents.sum | Requests to DynamoDB that exceed the provisioned write capacity units for a table or a global secondary index. | long | gauge |
| aws.tags | Tag key value pairs from aws resources. | flattened |  |
| cloud | Fields related to the cloud or infrastructure the events are coming from. | group |  |
| cloud.account.id | The cloud account or organization id used to identify different entities in a multi-tenant environment. Examples: AWS account id, Google Cloud ORG Id, or other unique identifier. | keyword |  |
| cloud.image.id | Image ID for the cloud instance. | keyword |  |
| cloud.region | Region in which this host, resource, or service is located. | keyword |  |
| data_stream.dataset | Data stream dataset. | constant_keyword |  |
| data_stream.namespace | Data stream namespace. | constant_keyword |  |
| data_stream.type | Data stream type. | constant_keyword |  |
| error | These fields can represent errors of any kind. Use them for errors that happen while fetching events or in cases where the event itself contains an error. | group |  |
| event.module | Event module | constant_keyword |  |
| host.containerized | If the host is a container. | boolean |  |
| host.os.build | OS build information. | keyword |  |
| host.os.codename | OS codename, if any. | keyword |  |
