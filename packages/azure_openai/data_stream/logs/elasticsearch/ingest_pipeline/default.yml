---
description: Pipeline for parsing azure open_ai logs.
processors:
  - rename:
      field: message
      target_field: event.original
      ignore_missing: true
      if: 'ctx.event?.original == null'
      description: 'Renames the original `message` field to `event.original` to store a copy of the original message. The `event.original` field is not touched if the document already has one; it may happen when Logstash sends the document.'
  - remove:
      field: message
      ignore_missing: true
      if: 'ctx.event?.original != null'
      description: 'The `message` field is no longer required if the document has an `event.original` field.'
  - json:
      field: event.original
      target_field: azure.open_ai
  - rename:
      field: azure.open_ai.resourceId
      target_field: azure.resource.id
      ignore_missing: true
  - drop:
      description: Drop non Azure OpenAI logs.
      if: "ctx.azure.open_ai.category != 'Audit' && ctx.azure.open_ai.category != 'RequestResponse' && ctx.azure.open_ai.category != 'GatewayLogs'"
      ignore_failure: true
  - json:
      tag: json-extract-stringly-Properties
      field: azure.open_ai.properties
      if: ctx.azure?.open_ai?.properties instanceof String
      on_failure:
        - remove:
            field: azure.open_ai.properties
        - append:
            field: error.message
            value: 'Processor {{{_ingest.on_failure_processor_type}}} with tag {{{_ingest.on_failure_processor_tag}}} in pipeline {{{_ingest.pipeline}}} failed with message: {{{_ingest.on_failure_message}}}'
  - script:
      description: Convert Azure JSON keys to snake case.
      tag: azure-json-keys-to-snake-case
      lang: painless
      source: |
        Map keysToSnakeCase(Map m) {
          def regex = /_?([a-z])([A-Z]+)/;
          def out = [:];

          for (entry in m.entrySet()) {
            def k = entry.getKey();
            def v = entry.getValue();

            if (v instanceof Map) {
              v = keysToSnakeCase(v);
            } else if (v instanceof List) {
              for (int i = 0; i < v.size(); i++) {
                def item = v.get(i);
                if (item instanceof Map) {
                  v.set(i, keysToSnakeCase(item));
                }
              }
            }

            k = regex.matcher(k).replaceAll('$1_$2').toLowerCase();
            out.put(k, v);
          }

          return out;
        }

        ctx.azure['open_ai'] = keysToSnakeCase(ctx.azure.open_ai);
  - json:
      field: azure.open_ai.properties.backend_request_body
      if: "ctx.azure?.open_ai?.properties?.backend_request_body instanceof String"
  # GatewayLogs: Extract the backend_request body content as key value pairs. Logs the actual request input, model name information.
  - script:
      lang: painless
      source: >-
        if (ctx.azure.open_ai.properties.backend_request != null) {
          ctx.temp_request = new HashMap();
          for (String key : ctx.azure.open_ai.properties.backend_request.keySet()) {
            ctx.temp_request[key.replace('.', '_')] = ctx.azure.open_ai.properties.backend_request.get(key);
          }
          ctx.azure.open_ai.properties.backend_request = ctx.temp_request; ctx.remove('temp_request');
        }
  - json:
      field: azure.open_ai.properties.backend_response_body
      if: "ctx.azure?.open_ai?.properties?.backend_response_body instanceof String"
      ignore_failure: true
  # GatewayLogs: Extract the backend_response body content as key value pairs. This logs the actual response input, usage tokens and the content filter information from the chat API.
  - script:
      lang: painless
      source: >-
        if (ctx.azure.open_ai.properties.backend_response != null) {
          ctx.temp_response = new HashMap();
          for (String key : ctx.azure.open_ai.properties.backend_response.keySet()) {
            ctx.temp_response[key.replace('.', '_')] = ctx.azure.open_ai.properties.backend_response.get(key);
          }
          ctx.azure.open_ai.properties.backend_response = ctx.temp_response; ctx.remove('temp_response');
        }
      ignore_failure: true
  - date:
      field: azure.open_ai.time
      target_field: '@timestamp'
      ignore_failure: true
      formats:
        - ISO8601
  - remove:
      field: azure.open_ai.time
      ignore_missing: true
  - convert:
      field: azure.open_ai.level
      target_field: log.level
      type: string
      tag: convert-level
      ignore_missing: true
  - remove:
      field: azure.open_ai.level
      ignore_missing: true
      tag: remove-level
  ## The conversion is done only for Gateway logs because the RequestResponse log caller_ip last octet is masked.
  - convert:
      field: azure.open_ai.caller_ip_address
      target_field: source.ip
      type: ip
      if: ctx.azure.open_ai.category == 'GatewayLogs'
      ignore_missing: true
      tag: convert-caller_ip_address
      on_failure:
        - rename:
            field: azure.open_ai.caller_ip_address
            target_field: source.address
            ignore_missing: true
            tag: rename-caller_ip_address
            on_failure:
              - append:
                  field: error.message
                  value: 'Processor {{{_ingest.on_failure_processor_type}}} with tag {{{_ingest.on_failure_processor_tag}}} in pipeline {{{_ingest.on_failure_pipeline}}} failed with message: {{{_ingest.on_failure_message}}}'
  - remove:
      field:
        - azure.open_ai.caller_ip_address
      if: ctx.source?.ip != null && ctx.azure.open_ai.category == 'GatewayLogs'
      tag: remove-gatewaylog-caller_ip_address
      ignore_missing: true
  - geoip:
      field: source.ip
      target_field: source.geo
      ignore_missing: true
  # IP Autonomous System (AS) Lookup
  - geoip:
      database_file: GeoLite2-ASN.mmdb
      field: source.ip
      target_field: source.as
      properties:
        - asn
        - organization_name
      ignore_missing: true
  - rename:
      field: source.as.asn
      target_field: source.as.number
      ignore_missing: true
  - rename:
      field: source.as.organization_name
      target_field: source.as.organization.name
      ignore_missing: true
  - set:
      field: event.outcome
      value: success
      if: ctx?.azure?.open_ai?.result_type != null && ctx?.azure?.open_ai?.result_type instanceof String && ctx?.azure?.open_ai?.result_type.toLowerCase() == "succeeded"
  - set:
      field: event.outcome
      value: failure
      if: ctx?.azure?.open_ai?.result_type != null && ctx?.azure?.open_ai?.result_type instanceof String && ctx?.azure?.open_ai?.result_type.toLowerCase() == "failed"
  - remove:
      field: azure.open_ai.result_type
      tag: remove-properties_result_type
      if: ctx.azure?.open_ai?.result_type != null && ctx.azure?.open_ai?.category == 'GatewayLogs'
      ignore_missing: true
  ## Make the request, response sizes fields same for both categories.
  - rename:
      field: azure.open_ai.properties.request_size
      target_field: azure.open_ai.properties.request_length
      ignore_missing: true
  - rename:
      field: azure.open_ai.properties.response_size
      target_field: azure.open_ai.properties.response_length
      ignore_missing: true
  - rename:
      field: azure.open_ai.properties.backend_response_body.usage.prompt_tokens
      target_field: azure.open_ai.properties.backend_response_body.usage.input_tokens
      ignore_missing: true
  - rename:
      field: azure.open_ai.properties.backend_response_body.usage.completion_tokens
      target_field: azure.open_ai.properties.backend_response_body.usage.output_tokens
      ignore_missing: true
  - rename:
      field: azure.open_ai.properties.method
      target_field: http.request.method
      ignore_missing: true
  - rename:
      field: azure.open_ai.properties.response_code
      target_field: http.response.status_code
      ignore_missing: true
  - uri_parts:
      field: azure.open_ai.properties.url
      if: ctx.azure?.open_ai?.properties?.url != null
      keep_original: true
      tag: uri_parts-properties-request_uri
      on_failure:
        - append:
            field: error.message
            value: 'Processor {{{_ingest.on_failure_processor_type}}} with tag {{{_ingest.on_failure_processor_tag}}} in pipeline {{{_ingest.on_failure_pipeline}}} failed with message: {{{_ingest.on_failure_message}}}'
  - remove:
      field: azure.open_ai.properties.url
      tag: remove-properties_url
      if: ctx.url?.original != null
      ignore_missing: true
  - remove:
      field:
        - azure.open_ai.properties.response_body
        - azure.open_ai.properties.request_body
      tag: remove-request-response-body
      ignore_missing: true
  - rename:
      field: azure.open_ai.duration_ms
      target_field: event.duration
      ignore_missing: true
  - script:
      lang: painless
      source: if (ctx.event.duration!= null) {ctx.event.duration = ctx.event.duration
        * params.param_nano;}
      params:
        param_nano: 1000000
      ignore_failure: true
  - pipeline:
      name: '{{ IngestPipeline "azure-shared-pipeline" }}'
      ignore_failure: true
  - remove:
      field: event.original
      if: "ctx?.tags == null || !(ctx.tags.contains('preserve_original_event'))"
      ignore_failure: true
      ignore_missing: true
  - script:
      description: Drops null/empty values recursively.
      lang: painless
      source: |
        boolean drop(Object o) {
          if (o == null || o == "") {
            return true;
          } else if (o instanceof Map) {
            ((Map) o).values().removeIf(v -> drop(v));
            return (((Map) o).size() == 0);
          } else if (o instanceof List) {
            ((List) o).removeIf(v -> drop(v));
            return (((List) o).length == 0);
          }
          return false;
        }
        drop(ctx);
on_failure:
  - set:
      field: error.message
      value: "{{ _ingest.on_failure_message }} {{ _ingest.on_failure_processor_type }}"
