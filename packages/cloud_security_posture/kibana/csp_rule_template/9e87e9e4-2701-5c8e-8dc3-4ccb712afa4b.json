{
    "id": "9e87e9e4-2701-5c8e-8dc3-4ccb712afa4b",
    "type": "csp-rule-template",
    "attributes": {
        "metadata": {
            "impact": "You require TLS to be configured on apiserver as well as kubelets.",
            "default_value": "See the EKS documentation for the default value.\n",
            "references": "1. https://kubernetes.io/docs/admin/kubelet/\n2. https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-authentication-authorization/\n3. https://kubernetes.io/docs/tasks/administer-cluster/reconfigure-kubelet/",
            "id": "9e87e9e4-2701-5c8e-8dc3-4ccb712afa4b",
            "name": "Ensure that the --client-ca-file argument is set as appropriate",
            "profile_applicability": "* Level 1",
            "description": "Enable Kubelet authentication using certificates.",
            "rationale": "The connections from the apiserver to the kubelet are used for fetching logs for pods, attaching (through kubectl) to running pods, and using the kubelet\u2019s port-forwarding functionality.\nThese connections terminate at the kubelet\u2019s HTTPS endpoint.\nBy default, the apiserver does not verify the kubelet\u2019s serving certificate, which makes the connection subject to man-in-the-middle attacks, and unsafe to run over untrusted and/or public networks.\nEnabling Kubelet certificate authentication ensures that the apiserver could authenticate the Kubelet before submitting any requests.",
            "audit": "**Audit Method 1:**\n\nIf using a Kubelet configuration file, check that there is an entry for `\"x509\": {\"clientCAFile:\"` set to the location of the client certificate authority file.\n\nFirst, SSH to the relevant node:\n\nRun the following command on each node to find the appropriate Kubelet config file:\n\n```\nps -ef | grep kubelet\n```\nThe output of the above command should return something similar to `--config /etc/kubernetes/kubelet/kubelet-config.json` which is the location of the Kubelet config file.\n\nOpen the Kubelet config file:\n```\nsudo more /etc/kubernetes/kubelet/kubelet-config.json\n```\n\nVerify that the `\"x509\": {\"clientCAFile:\"` argument exists and is set to the location of the client certificate authority file.\n\nIf the `\"x509\": {\"clientCAFile:\"` argument is not present, check that there is a Kubelet config file specified by `--config`, and that the file sets `\"authentication\": { \"x509\": {\"clientCAFile:\"` to the location of the client certificate authority file.\n\n**Audit Method 2:**\n\nIf using the api configz endpoint consider searching for the status of `authentication..\nx509\":(\"clientCAFile\":\"/etc/kubernetes/pki/ca.crt` by extracting the live configuration from the nodes running kubelet.\n\nSet the local proxy port and the following variables and provide proxy port number and node name;\n`HOSTNAME_PORT=\"localhost-and-port-number\"`\n`NODE_NAME=\"The-Name-Of-Node-To-Extract-Configuration\" from the output of \"kubectl get nodes\"`\n```\nkubectl proxy --port=8001 &\n\nexport HOSTNAME_PORT=localhost:8001 (example host and port number)\nexport NODE_NAME=ip-192.168.31.226.ec2.internal (example node name from \"kubectl get nodes\")\n\ncurl -sSL \"http://${HOSTNAME_PORT}/api/v1/nodes/${NODE_NAME}/proxy/configz\"\n```",
            "remediation": "**Remediation Method 1:**\n\nIf modifying the Kubelet config file, edit the kubelet-config.json file `/etc/kubernetes/kubelet/kubelet-config.json` and set the below parameter to false\n\n```\n\"authentication\": { \"x509\": {\"clientCAFile:\" to the location of the client CA file.\n``` \n\n**Remediation Method 2:**\n\nIf using executable arguments, edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` on each worker node and add the below parameter at the end of the `KUBELET_ARGS` variable string.\n\n```\n--client-ca-file=<path/to/client-ca-file>\n```\n\n**Remediation Method 3:**\n\nIf using the api configz endpoint consider searching for the status of `\"authentication.*x509\":(\"clientCAFile\":\"/etc/kubernetes/pki/ca.crt\"` by extracting the live configuration from the nodes running kubelet.\n\n**See detailed step-by-step configmap procedures in [Reconfigure a Node's Kubelet in a Live Cluster](https://kubernetes.io/docs/tasks/administer-cluster/reconfigure-kubelet/), and then rerun the curl statement from audit process to check for kubelet configuration changes\n```\nkubectl proxy --port=8001 &\n\nexport HOSTNAME_PORT=localhost:8001 (example host and port number)\nexport NODE_NAME=ip-192.168.31.226.ec2.internal (example node name from \"kubectl get nodes\")\n\ncurl -sSL \"http://${HOSTNAME_PORT}/api/v1/nodes/${NODE_NAME}/proxy/configz\"\n```\n\n**For all three remediations:**\nBased on your system, restart the `kubelet` service and check status\n\n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\nsystemctl status kubelet -l\n```\n```",
            "section": "Kubelet",
            "version": "1.0",
            "tags": [
                "CIS",
                "EKS",
                "CIS 3.2.3",
                "Kubelet"
            ],
            "benchmark": {
                "name": "CIS Amazon Elastic Kubernetes Service (EKS)",
                "version": "v1.0.1",
                "id": "cis_eks",
                "rule_number": "3.2.3",
                "posture_type": "kspm"
            },
            "rego_rule_id": "cis_3_2_3"
        }
    },
    "migrationVersion": {
        "csp-rule-template": "8.7.0"
    },
    "coreMigrationVersion": "8.7.0"
}