# Bitsight Vulnerability → Evidence three-stage integration
# This cel.yml.hbs implements a depth-first (LIFO) work-queue that walks the
# Bitsight Threats API in three nested levels:
#   1) Threat list   (/ratings/v2/threats)                           - A-level
#   2) Companies per threat (/ratings/v2/threats/{t}/companies)      - B-level
#   3) Evidence  per company (/ratings/v2/threats/{t}/companies/{c}/evidence) - C-level
# The queue lives in `state.jobs` and each run processes **exactly one** job -
# this keeps memory stable and lets the Agent resume cleanly after restarts.
# New child jobs are *prepended* to the list (LIFO) so we always finish a
# branch before moving on to the next threat.
#
# Cursor logic:
#  • `cursor.last_first_seen_date` remembers the date we last started from.
#  • On the very first run we look back `initial_interval` (e.g. "720h").
#  • At the end of a full cycle (queue empty) we persist the **same** start
#    date - this way the next schedule begins where the previous left off.
#
# Authentication:
#  • Bitsight uses *Basic* auth with the API token as the **username** and an
#    empty password.  We build the header once per request.
#
# Error handling:
#  • All HTTP are logged as error events with the status code and message.
#  • The failed job is *dropped* so we don't loop forever.
#
# Pagination:
#  • Every endpoint supports `limit` + `links.next` full URL.  We enqueue the
#    `links.next` URL (same job type) whenever it is present and non-empty.
#
# Output events:
#  • Each evidence row becomes **one** JSON document:
#    {
#      "threat": { full threat JSON },
#      "company": { full company JSON },
#      "evidence": { evidence row JSON }
#    }
config_version: 2
interval: {{interval}}
resource.tracer:
  enabled: {{enable_request_tracer}}
  filename: "../../logs/cel/http-request-trace-*.ndjson"
  maxbackups: 5
{{#if proxy_url}}
resource.proxy_url: {{proxy_url}}
{{/if}}
{{#if ssl}}
resource.ssl: {{ssl}}
{{/if}}
{{#if http_client_timeout}}
resource.timeout: {{http_client_timeout}}
{{/if}}
resource.url: {{url}}
{{#if resource_rate_limit_limit}}
resource.rate_limit.limit: {{resource_rate_limit_limit}}
{{/if}}
{{#if resource_rate_limit_burst}}
resource.rate_limit.burst: {{resource_rate_limit_burst}}
{{/if}}

{{#if resource_retry_max_attempts}}
resource.retry.max_attempts: {{resource_retry_max_attempts}}
{{/if}}

{{#if resource_retry_wait_min}}
resource.retry.wait_min: {{resource_retry_wait_min}}
{{/if}}

{{#if resource_retry_wait_max}}
resource.retry.wait_max: {{resource_retry_wait_max}}
{{/if}}

state:
  url: {{url}} 
  token: {{token}}
  batch_size: {{batch_size}}
  initial_interval: {{initial_interval}}  # e.g. "720h" (=30 days)
  preserve_original_event: {{preserve_original_event}}

redact:
  fields:
    - token

program: |-
  (
    //    Build the job queue
    //    First, ensure start_date exists
    //    Use previous state if we are in a pagination want_more cycle
    //    Otherwise its a new run and we use the stored cursor or the initial interval
    state.with({
      "start_date": state.?start_date.orValue(
        state.?cursor.last_first_seen_date.orValue(
          (now - duration(state.initial_interval)).format("2006-01-02")
        )
      )
    })
    .as(state, state.with(
      // If we are in a pagination cycle, the jobs are already set
      has(state.jobs) && size(state.jobs) > 0 ?
        state
      :
        // If we have a new run, we need to build the job queue
        // We use the start_date to build the first job
        {
          "jobs": [{
            "type": "threats_page",
            "url": state.url.trim_right("/") + "/ratings/v2/threats?" + {
              "category_slug": ["vulnerability"],
              "first_seen_date_gte": [state.start_date],
              "limit": [string(state.batch_size)],
              "sort" : ["first_seen_date"]
            }.format_query()
          }]
        }
    ))
  )
  .as(state, state.with(
    //    Dequeue the first job (LIFO) and dispatch on its `type`.
    //    We *always* build a new output map that contains at minimum
    //    `jobs`, `events`.
    //    We have the state.with in scope here so we preserve all other
    //    state variables which we dont explicitly change.
    state.jobs[0].as(job,
      job.?url.orValue(null) != null ? (
        // A:  Threats page  →  enqueue companies jobs + maybe next page
        job.type == "threats_page" ?
          request("GET", job.url).with({
            "Header": {"Authorization": ["Basic " + (state.token + ":").base64()]}
          }).do_request().as(resp,
            resp.StatusCode == 200 ?
              resp.Body.decode_json().as(body,
                has(body.results) && size(body.results) > 0 ?
                  // We need to build a new company job for each threat
                  // and add it to the job queue
                  body.results.map(t, {
                    "type": "companies_page",
                    "threat": t,
                    "url": state.url.trim_right("/") + "/ratings/v2/threats/" + t.guid + "/companies?" + {
                      "limit": [string(state.batch_size)]
                    }.format_query()
                  }).as(company_jobs,
                    // We also need to check if there is a next page
                    // and add it as a threats_page job
                    {
                      "events": [{"message": string({"event": {"reason": "polling"}}.encode_json())}],
                      "jobs": company_jobs +
                        (has(body.?links.next) && body.links.next != null && body.links.next != "" ?
                          [{"type": "threats_page", "url": body.links.next}] : []) +
                        tail(state.jobs),
                      "want_more": true
                    }
                  )
                :
                  {
                    "events": {
                      "error": {
                        "code": string(resp.StatusCode),
                        "id": string(resp.Status),
                        "message": "GET " + state.url.trim_right("/") + "/ratings/v2/threats/ job: " + (
                          size(resp.Body) != 0 ?
                            string(resp.Body)
                          :
                            string(resp.Status) + " (" + string(resp.StatusCode) + ")"
                        )
                      }
                    },
                    // We need to drop the faulty job and continue with the next one
                    "jobs": tail(state.jobs),
                    "want_more": true
                  }
              )
            :
              {
                "events": {
                  "error": {
                    "code": string(resp.StatusCode),
                    "id": string(resp.Status),
                    "message": "GET " + state.url.trim_right("/") + "/ratings/v2/threats/: " + (
                      size(resp.Body) != 0 ?
                        string(resp.Body)
                      :
                        string(resp.Status) + " (" + string(resp.StatusCode) + ")"
                    )
                  }
                },
                // We need to drop the faulty job and continue with the next one
                "jobs": tail(state.jobs),
                // Do not continue if we get a 429 or 500+ error since this might be a temporary issue
                // and we don't want to spam the API with requests
                // Neither do we want to lose the job queue and overwrite the cursor at the end
                "want_more": resp.StatusCode != 429 && resp.StatusCode < 500
              }
          )
        :
          // B:  Companies page  →  enqueue evidence jobs + maybe next page
          job.type == "companies_page" ?
          request("GET", job.url).with({
            "Header": {"Authorization": ["Basic " + (state.token + ":").base64()]}
          }).do_request().as(resp,
            resp.StatusCode == 200 ?
              resp.Body.decode_json().as(body,
                has(body.results) && size(body.results) > 0 ?
                  body.results.map(c, {
                    "type": "evidence_page",
                    "threat": job.threat,
                    "company": c,
                    "url": state.url.trim_right("/") + "/ratings/v2/threats/" + job.threat.guid + "/companies/" + c.company_guid + "/evidence?" + {
                      "limit": [string(state.batch_size)]
                    }.format_query()
                  }).as(ev_jobs,
                    {
                      "events": [{"message": string({"event": {"reason": "polling"}}.encode_json())}],
                      "jobs": ev_jobs +
                        (has(body.?links.next) && body.links.next != null && body.links.next != "" ?
                          [{"type": "companies_page", "threat": job.threat, "url": body.links.next}] : []) +
                        tail(state.jobs),
                      "want_more": true
                    }
                  )
                :
                  // There are no company records for this threat
                  // We simply emit the threat and continue with the next one
                  (
                    {
                      "threat":  job.threat
                    }.as(msg,
                      {
                        "events": {
                          "message": string(msg.encode_json())
                        },
                        // No need to enqueue a new job, we just continue with the next one
                        "jobs": tail(state.jobs),
                        // We can still set the last_first_seen_date here
                        "cursor": { "last_first_seen_date":  job.threat.first_seen_date},
                        "want_more": true
                      }
                    )
                  )
              )
            :
              {
                "events": {
                  "error": {
                    "code": string(resp.StatusCode),
                    "id": string(resp.Status),
                    "message": "GET " + string(job.url) + ": " + (
                      size(resp.Body) != 0 ?
                        string(resp.Body)
                      :
                        string(resp.Status) + " (" + string(resp.StatusCode) + ")"
                    )
                  }
                },
                // We need to drop the faulty job and continue with the next one
                "jobs": tail(state.jobs),
                "want_more": resp.StatusCode != 429 && resp.StatusCode < 500
              }
          )
        :
          // C: Evidence page  →  emit events + maybe next page
          job.type == "evidence_page" ?
          request("GET", job.url).with({
            "Header": {"Authorization": ["Basic " + (state.token + ":").base64()]}
          }).do_request().as(resp,
            resp.StatusCode == 200 ?
              resp.Body.decode_json().as(body,
                has(body.results) && size(body.results) > 0 ?
                  body.results.map(e,
                    {
                      "threat":  job.threat,
                      "company": job.company,
                      "evidence": e
                    }.as(msg,
                      {
                        "message": string(msg.encode_json())
                      }
                    )
                  ).as(evts,
                    {
                      "events": evts,
                      "jobs":
                        (has(body.?links.next) && body.links.next != null && body.links.next != "" ?
                          [{"type": "evidence_page", "threat": job.threat, "company": job.company, "url": body.links.next}] : []) +
                        tail(state.jobs),
                        // We can just set the last_first_seen_date here
                        // because we sort the jobs by first_seen_date acscending
                        // every further job will always be later than this one and replace it
                      "cursor": { "last_first_seen_date":  job.threat.first_seen_date},
                      "want_more": true
                    }
                  )
                :
                  // There are no evidence records for this company
                  // We simply emit the threat and company and continue with the next one
                  (
                    {
                      "threat":  job.threat,
                      "company": job.company
                    }.as(msg,
                      {
                        "events": {
                          "message": string(msg.encode_json())
                        },
                        // No need to enqueue a new job, we just continue with the next one
                        "jobs": tail(state.jobs),
                        // We can still set the last_first_seen_date here
                        "cursor": { "last_first_seen_date":  job.threat.first_seen_date},
                        "want_more": true
                      }
                    )
                  )
              )
            :
              {
                "events": {
                  "error": {
                    "code": string(resp.StatusCode),
                    "id": string(resp.Status),
                    "message": "GET " + string(job.url) + ": " + (
                      size(resp.Body) != 0 ?
                        string(resp.Body)
                      :
                        string(resp.Status) + " (" + string(resp.StatusCode) + ")"
                    )
                  }
                },
                // We need to drop the faulty job and continue with the next one
                "jobs": tail(state.jobs),
                "want_more": resp.StatusCode != 429 && resp.StatusCode < 500
              }
          )
        :
          // D:  Unknown job type - should never happen, drop & continue
          {
            "events": {
              "error": {
                "message": "Unknown job type: " + string(job)
              }
            },
            "jobs": tail(state.jobs),
            "want_more": true
          }
        )
      :
        // The job url is null, we need to drop the job and continue with the next one
        {
          "events": {
            "error": {
              "message": "Job url is null: " + string(job)
            }
          },
          "jobs": tail(state.jobs),
          "want_more": true
        }
    )
  ))
  .as(state, state.with(
    //    When the queue is completely empty we finish the cycle
    size(state.jobs) == 0 ?
      {
        "want_more": false
      }
    :
      // We just emit the already created output and dont add anything else
      {}
  ))

tags:
{{#if preserve_original_event}}
  - preserve_original_event
{{/if}}
{{#each tags as |tag|}}
  - {{tag}}
{{/each}}
{{#contains "forwarded" tags}}
publisher_pipeline.disable_host: true
{{/contains}}
{{#if processors}}
processors:
{{processors}}
{{/if}}
