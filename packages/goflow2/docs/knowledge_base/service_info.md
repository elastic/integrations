# Service Info

## Common use cases

The GoFlow2 integration is designed to ingest and normalize network flow data, specifically focusing on the sFlow protocol. It enables organizations to gain deep visibility into network traffic patterns, bandwidth usage, and potential security threats.

- **Network Traffic Monitoring:** Gain real-time visibility into high-volume network traffic by collecting sFlow data from routers and switches, allowing for detailed analysis of source and destination patterns.
- **Security Analysis:** Identify anomalous traffic behavior or potential DDoS attacks by monitoring flow data and analyzing packet headers and protocol distributions.
- **Bandwidth Management:** Track bandwidth consumption across different interfaces and VLANs to identify top talkers and optimize network resource allocation.
- **Compliance and Auditing:** Maintain long-term records of network flows for regulatory compliance and forensic investigations following security incidents.

## Data types collected

This integration collects network flow data by monitoring JSON log files generated by the GoFlow2 collector. The following data types and streams are available:

- **sFlow logs (Data Stream):** Titled **sFlow logs**, this data stream collects sFlow logs from GoFlow2. It captures detailed records of sampled network traffic, including packet headers and flow metadata, and ingests them into the `goflow2.sflow` dataset.
- **Network Metadata:** Information such as source and destination IP addresses, source and destination ports, and VLAN tags.
- **Flow Statistics:** Data regarding the number of bytes and packets transferred in a specific flow.
- **Log Format:** All data is collected in **JSON** format, specifically mapped to ensure compatibility with the Elastic Common Schema (ECS).
- **Log Path:** The integration monitors the `/var/log/sflow/goflow2/*.log` path by default to ingest the formatted JSON output from the GoFlow2 collector.

## Compatibility

The **GoFlow2** integration is compatible with the following:
- **GoFlow2** binary versions that support the `-mapping` and `-transport.file` flags, such as version 2.1.2 or later.
- Network infrastructure devices (switches, routers, firewalls) capable of exporting **sFlow** (versions 2, 4, or 5).
- **Note:** This integration specifically supports sFlow normalization only; NetFlow and IPFIX protocols are currently unsupported for normalization.

## Scaling and Performance

To ensure optimal performance in high-volume environments, consider the following:
- **Transport/Collection Considerations:** The integration uses the `filestream` input to monitor local log files generated by the GoFlow2 binary. Ensure that the disk subsystem has sufficient I/O performance to handle simultaneous writes from the GoFlow2 collector and reads by the Elastic Agent. Use a robust log rotation strategy (e.g., `logrotate`) to prevent disk exhaustion, ensuring that the Elastic Agent has sufficient time to harvest logs before they are purged.
- **Data Volume Management:** In high-density network environments, it is critical to tune the sFlow sampling rate at the source (network hardware). A sampling rate of 1 in 1000 or 1 in 5000 is often sufficient for traffic analysis while significantly reducing the CPU load on the GoFlow2 collector and the event volume processed by the Elastic Agent.
- **Elastic Agent Scaling:** For high-throughput environments, deploy the Elastic Agent on a dedicated host with multiple CPU cores to handle JSON parsing. If a single collector becomes a bottleneck, distribute your network devices across multiple GoFlow2 collectors and Elastic Agents to load-balance the ingest pipeline.

# Set Up Instructions

## Vendor prerequisites

1. **Administrative Access:** You must have root or sudo privileges on the Linux server where GoFlow2 and the Elastic Agent will be installed.
2. **Network Connectivity:** Port `6343/UDP` must be open on the host firewall to receive sFlow traffic from network devices.
3. **Binary Installation:** The GoFlow2 binary must be downloaded and placed in the system execution path (e.g., `/usr/local/bin/`).
4. **Directory Permissions:** The directory `/var/log/sflow/goflow2/` must exist and be writable by the GoFlow2 process and readable by the Elastic Agent.
5. **Network Device Configuration:** Access to the network switches or routers is required to configure them to export sFlow data to the collector's IP address.

## Elastic prerequisites

1. **Elastic Stack Version:** Ensure you are running an Elastic Stack version that supports Elastic Agent and Fleet (version 7.14.0 or higher is recommended).
2. **Elastic Agent:** Must be installed and enrolled in a policy via Fleet.
3. **Network Connectivity:** The Elastic Agent must have network access to the Elasticsearch cluster to ship logs.
4. **File Access:** The Elastic Agent must have permissions to read files in the `/var/log/sflow/goflow2/` directory.

## Vendor set up steps

### For Log-based Collection (GoFlow2 Binary):

1. **Install GoFlow2 Binary:**
   Download the latest release and move it to your bin directory:
   ```bash
   wget https://github.com/netsampler/goflow2/releases/download/v2.2.6/goflow2-2.2.6-linux-amd64.tar.gz
   tar -xzvf goflow2_2.2.6_linux_amd64.tar.gz
   sudo mv goflow2 /usr/local/bin/
   sudo chmod +x /usr/local/bin/goflow2
   ```

2. **Prepare Directories:**
   Create the configuration and log directories:
   ```bash
   sudo mkdir -p /etc/goflow2
   sudo mkdir -p /var/log/sflow/goflow2
   ```

3. **Configure the Mapping File:**
   Create `/etc/goflow2/mapping.yaml` to ensure JSON fields match the integration's expectations:
   ```yaml
   formatter:
       fields:
           - type
           - time_flow_start_ns
           - sampler_address
           - sequence_num
           - in_if
           - out_if
           - src_addr
           - dst_addr
           - etype
           - proto
           - src_port
           - dst_port
           - src_vlan
           - dst_vlan
           - sampling_rate
           - bytes
   ```

4. **Setup Systemd Service:**
   Create `/etc/systemd/system/goflow2.service` with the following configuration:
   ```ini
   [Unit]
   Description=GoFlow2 sFlow Collector
   After=network.target

   [Service]
   Type=simple
   ExecStart=/usr/local/bin/goflow2 \
       -format json \
       -listen "sflow://:6343" \
       -mapping /etc/goflow2/mapping.yaml \
       -transport.file /var/log/sflow/goflow2/goflow2.log
   Restart=always
   RestartSec=5

   [Install]
   WantedBy=multi-user.target
   ```

5. **Start the Collector:**
   Reload systemd, enable, and start the service:
   ```bash
   sudo systemctl daemon-reload
   sudo systemctl enable --now goflow2
   ```

6. **Configure Network Exporters:**
   Log into your network devices (switches/routers) and configure the sFlow destination to the IP of this server on UDP port `6343`.

### Vendor Set up Resources

- [GoFlow2 GitHub Repository](https://github.com/netsampler/goflow2) - Official source code and release page for GoFlow2.
- [GoFlow2 Configuration Guide - DeepWiki](https://deepwiki.com/netsampler/goflow2/2.2-configuration) - Detailed configuration parameters and command-line options for GoFlow2.

## Kibana set up steps

1. In Kibana, navigate to **Management > Integrations**.
2. Search for and select **GoFlow2**.
3. Click **Add GoFlow2**.
4. Configure the **Collecting logs via log file** input:
    - **Paths**: Specify the list of paths to the log files that contain sFlow logs. Default: `['/var/log/sflow/goflow2/*.log']`.
    - **Preserve original event**: Toggle this to preserve a raw copy of the original event in the `event.original` field. Default: `False`.
    - **Ignore events older than**: Set the duration to ignore events older than a specific time. Valid units: `ns`, `us`, `ms`, `s`, `m`, `h`. Default: `72h`.
    - **Exclude files**: Add [RE2 syntax](https://github.com/google/re2/wiki/Syntax) regular expressions to match files that should be excluded. See [exclude_files](https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-input-log.html#filebeat-input-log-exclude-files) for details. Default: `['\\.gz$']`.
    - **Tags**: Add custom tags to append to the events. Default: `['sflow', 'forwarded']`.
    - **Custom Filestream Options**: Provide additional configuration options for the filestream input. See [filestream input](https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-input-filestream.html) for details.
    - **Processors**: Define processors to enhance or filter data at the agent level. See [Processors](https://www.elastic.co/guide/en/beats/filebeat/current/filtering-and-enhancing-data.html) for details. Default: `- add_locale: ~`.
5. Provide a **Name** and **Description** for the integration instance.
6. Select the **Agent Policy** to which you want to add the integration.
7. Click **Save and continue**.

# Validation Steps

After configuration is complete, verify that data is flowing correctly.

### 1. Trigger Data Flow on goflow2:
- **Generate Network Traffic:** Initiate traffic through a network device configured to export sFlow (e.g., run a ping sweep or a large file transfer through the switch).
- **Verify Log Generation:** Check that GoFlow2 is actively writing to the log file by running `tail -f /var/log/sflow/goflow2/goflow2.log`.
- **Restart Service:** Restart the GoFlow2 service to generate initial startup logs: `sudo systemctl restart goflow2`.
- **Check UDP Reception:** Confirm the server is receiving traffic on the sFlow port by running `sudo tcpdump -i any udp port 6343`.

### 2. Check Data in Kibana:
1. Navigate to **Analytics > Discover**.
2. Select the `logs-*` data view.
3. Enter the KQL filter: `data_stream.dataset : "goflow2.sflow"`
4. Verify logs appear. Expand a log entry and confirm these fields are populated:
   - `event.dataset` (should be `goflow2.sflow`)
   - `source.ip`
   - `destination.ip`
   - `event.action` or `event.outcome`
   - `message`
5. Navigate to **Analytics > Dashboards** and search for "GoFlow2" to view pre-built visualizations.

# Troubleshooting

## Common Configuration Issues

- **Log File Permissions**: If the Elastic Agent cannot read the logs, it will not ingest data. Ensure the user running the Elastic Agent has read access to `/var/log/sflow/goflow2/` and that the GoFlow2 process has write permissions.
- **UDP Port Conflict**: If the GoFlow2 service fails to start, check if another process is already bound to port `6343/UDP` using `sudo netstat -tulpn | grep 6343`.
- **Mapping.yaml Formatting**: YAML is sensitive to indentation. If GoFlow2 fails to parse the mapping file, ensure it matches the exact structure provided in the setup steps.
- **Mismatched File Paths**: Ensure the **Paths** variable provided in the Kibana integration configuration matches the `-transport.file` path in the GoFlow2 systemd service.

## Ingestion Errors

- **Parsing Failures**: If logs appear in Kibana but fields are not correctly mapped, check the `error.message` field in the log entry. This often indicates that the GoFlow2 output does not match the integration's expected JSON structure.
- **Empty Logs**: If the log file exists but is empty, verify that the network devices are successfully reaching the collector on port 6343/UDP using `tcpdump -i any udp port 6343`.
- **Protocol Not Supported**: If you attempt to send NetFlow or IPFIX data, GoFlow2 may log errors or output data that the integration pipeline cannot process, as only sFlow is currently supported.

## Vendor Resources

- [GoFlow2 GitHub Repository](https://github.com/netsampler/goflow2)

# Documentation sites

- [GoFlow2 GitHub Repository](https://github.com/netsampler/goflow2)
- Refer to the official vendor website for further documentation.
